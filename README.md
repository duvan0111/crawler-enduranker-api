# EduRanker Crawler API

Backend FastAPI pour le projet EduRanker avec syst√®me de crawling, recherche vectorielle et reranking intelligent.

## üéØ Fonctionnalit√©s

- **API REST compl√®te** avec FastAPI
- **Crawler de ressources √©ducatives** depuis Wikipedia, GitHub, Medium
- **Recherche vectorielle FAISS** avec embeddings de pointe
- **Reranking intelligent** avec cross-encoder (Sentence-BERT)
- **Syst√®me d'inf√©rence** : tracking automatique de toutes les recommandations
- **Feedback simplifi√©** : 2 champs seulement (inference_id + feedback_type)
- **Fine-tuning** : am√©lioration continue du mod√®le avec les feedbacks
- **Base de donn√©es MongoDB** pour le stockage
- **Documentation interactive** avec Swagger UI
- **Architecture MVC** (Models, Views, Controllers)
- **Tests automatis√©s** et scripts d'analyse

## üìÅ Structure du projet

```
crawler-enduranker-api/
‚îú‚îÄ‚îÄ public/                    # Fichiers statiques
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ crawler/              # Syst√®me de crawling Scrapy
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ spiders/          # Spiders Wikipedia, GitHub, Medium
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils/            # Utilitaires de crawling
‚îÇ   ‚îú‚îÄ‚îÄ controllers/          # Logique de contr√¥le
‚îÇ   ‚îú‚îÄ‚îÄ models/               # Mod√®les Pydantic
‚îÇ   ‚îú‚îÄ‚îÄ routes/               # Routes API
‚îÇ   ‚îú‚îÄ‚îÄ services/             # Logique m√©tier
‚îÇ   ‚îî‚îÄ‚îÄ database.py           # Configuration MongoDB
‚îú‚îÄ‚îÄ venv/                     # Environnement virtuel
‚îú‚îÄ‚îÄ main.py                   # Point d'entr√©e
‚îú‚îÄ‚îÄ scrapy.cfg               # Configuration Scrapy
‚îú‚îÄ‚îÄ requirements.txt         # D√©pendances
‚îî‚îÄ‚îÄ .env                     # Variables d'environnement
```

## Installation

1. Cr√©er et activer l'environnement virtuel :
```bash
python3 -m venv venv
source venv/bin/activate  # Sur Linux/Mac
# ou
venv\Scripts\activate  # Sur Windows
```

2. Installer les d√©pendances :
```bash
pip install -r requirements.txt
```

3. Configurer les variables d'environnement :
```bash
cp .env.example .env
# Puis √©diter le fichier .env selon votre configuration
```

## Configuration de MongoDB

Assurez-vous que MongoDB est install√© et en cours d'ex√©cution localement :

```bash
# V√©rifier si MongoDB est en cours d'ex√©cution
sudo systemctl status mongod

# D√©marrer MongoDB si n√©cessaire
sudo systemctl start mongod

# Activer MongoDB au d√©marrage
sudo systemctl enable mongod
```

Par d√©faut, l'application se connecte √† `mongodb://localhost:27017` avec la base de donn√©es `eduranker_db`.
Vous pouvez modifier ces valeurs dans le fichier `.env` :

```env
MONGODB_URL=mongodb://localhost:27017
MONGODB_DB_NAME=eduranker_db
```

## Lancement

```bash
python main.py
# ou
uvicorn main:app --reload
```

L'API sera accessible sur `http://localhost:8000`

La documentation interactive sera disponible sur :
- Swagger UI : `http://localhost:8000/docs`
- ReDoc : `http://localhost:8000/redoc`

## üöÄ Utilisation de l'API Crawler

### Collecter des ressources √©ducatives

La route principale vous permet d'envoyer une question et de recevoir une liste d'articles/ressources :

```bash
curl -X POST "http://localhost:8000/api/crawler/collect" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "machine learning en √©ducation"
  }'
```

**Avec param√®tres personnalis√©s :**

```bash
curl -X POST "http://localhost:8000/api/crawler/collect" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "deep learning",
    "max_par_site": 10,
    "sources": ["wikipedia", "github"],
    "langues": ["fr", "en"]
  }'
```

### Rechercher dans les ressources existantes

```bash
curl -X POST "http://localhost:8000/api/crawler/search" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "machine learning",
    "limite": 20
  }'
```

### Scripts de test

Pour tester rapidement l'API :

```bash
# Test de l'API CRUD de base
./test_api.sh

# Test de l'API Crawler
./test_crawler_api.sh
```

## Test de la connexion MongoDB

Pour v√©rifier que MongoDB fonctionne correctement :

```bash
# Test de connexion MongoDB
mongosh

# Dans le shell MongoDB
show dbs
use eduranker_db
show collections
```

## üÜï Syst√®me d'Inf√©rence et Feedback

Le syst√®me de **tracking d'inf√©rence** et de **feedback simplifi√©** est maintenant op√©rationnel ! üéâ

### D√©marrage Rapide (3 √©tapes)

```bash
# 1. Cr√©er les index MongoDB (une seule fois)
python scripts/create_inference_indexes.py

# 2. D√©marrer l'API
python main.py

# 3. Tester le syst√®me (dans un autre terminal)
python scripts/test_inference_flow.py
```

### Fonctionnalit√©s Cl√©s

- ‚úÖ **Tracking automatique** : Toutes les recommandations sont sauvegard√©es
- ‚úÖ **Feedback simplifi√©** : Seulement 2 champs (`inference_id` + `feedback_type`)
- ‚úÖ **Analyse de performance** : Scripts d'analyse des donn√©es
- ‚úÖ **Fine-tuning** : Pr√©paration pour am√©lioration du mod√®le

### Endpoints Disponibles

```bash
# Recherche avec reranking (sauvegarde automatique des inf√©rences)
POST /api/reranking/search-with-reranking
{
  "query_text": "machine learning tutorial",
  "session_id": "user_123"  // Optionnel
}

# Soumission de feedback (ULTRA-SIMPLIFI√â)
POST /api/reranking/feedback
{
  "inference_id": "67567xyz...",  // De la r√©ponse de recherche
  "feedback_type": "like"          // "like" | "dislike" | "click" | "view"
}

# R√©cup√©ration des inf√©rences
GET /api/reranking/inferences/{query_id}
```

### Tests Disponibles

```bash
# Test complet (recherche + feedbacks multiples + v√©rification)
python scripts/test_inference_flow.py

# Test rapide (1 recherche + 1 feedback)
python scripts/test_inference_flow.py --quick

# Test bash (si jq install√©)
./scripts/test_quick.sh

# Analyser les donn√©es collect√©es
python scripts/analyze_inferences.py
```

### Documentation Compl√®te

| Document | Description |
|----------|-------------|
| **`QUICK_START.md`** | üöÄ Guide de d√©marrage en 5 minutes |
| **`docs/TESTING_INFERENCE_FEEDBACK.md`** | üß™ Guide de test complet |
| **`docs/FEEDBACK_SIMPLIFIE.md`** | üé® Int√©gration frontend |
| **`docs/INFERENCE_TRACKING.md`** | üë®‚Äçüíª Documentation technique |
| **`scripts/README.md`** | üîß Utilisation des scripts |
| **`IMPLEMENTATION_COMPLETE.md`** | üìä Vue d'ensemble syst√®me |
| **`FILES_SUMMARY.txt`** | üì¶ R√©sum√© des fichiers |

### Exemple d'Int√©gration Frontend

```javascript
// 1. Recherche
const response = await fetch('/api/reranking/search-with-reranking', {
  method: 'POST',
  body: JSON.stringify({ query_text: userQuery, session_id: sessionId })
});
const { results } = await response.json();

// 2. Afficher les r√©sultats et ajouter handlers
results.forEach(result => {
  // Stocker l'inference_id pour chaque r√©sultat
  const inferenceId = result.inference_id;
  
  // Sur like/dislike
  likeButton.onclick = () => submitFeedback(inferenceId, 'like');
  
  // Sur clic de la ressource
  resourceLink.onclick = () => submitFeedback(inferenceId, 'click');
});

// 3. Fonction de soumission
async function submitFeedback(inferenceId, feedbackType) {
  await fetch('/api/reranking/feedback', {
    method: 'POST',
    body: JSON.stringify({ inference_id: inferenceId, feedback_type: feedbackType })
  });
}
```

### Base de Donn√©es MongoDB

**Collection `inference`** : Stocke toutes les recommandations
```javascript
{
  "_id": ObjectId("..."),
  "user_query_id": "...",     // ID de la requ√™te
  "resource_id": "...",        // ID de la ressource recommand√©e
  "faiss_score": 0.85,         // Score FAISS
  "reranking_score": 0.92,     // Score cross-encoder
  "final_score": 0.88,         // Score final
  "rank": 1,                   // Position (1-N)
  "feedback": "like",          // Feedback utilisateur
  "date_inference": ISODate,   // Date de recommandation
  "date_feedback": ISODate,    // Date du feedback
  "session_id": "..."          // Session utilisateur
}
```

**5 index cr√©√©s** pour optimiser les performances :
- `user_query_id` - R√©cup√©ration rapide
- `resource_id` - Analyse par ressource
- `feedback` - Statistiques
- `session_id` - Suivi utilisateur
- `date_inference` - Tri chronologique

### Prochaines √âtapes

1. **Collecter des donn√©es** : Laisser le syst√®me tourner et collecter des feedbacks
2. **Analyser** : `python scripts/analyze_inferences.py`
3. **Fine-tuner** : `POST /api/reranking/fine-tune?num_epochs=3`
4. **Optimiser** : Ajuster le mod√®le en fonction des r√©sultats
