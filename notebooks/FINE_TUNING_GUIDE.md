# ğŸ““ Fine-Tuning via Jupyter Notebook - Guide Complet

## ğŸ¯ Vue d'Ensemble

Le **fine-tuning du cross-encoder** se fait dÃ©sormais via un **Jupyter Notebook interactif** plutÃ´t que via l'API. Cette approche offre de nombreux avantages :

âœ… **Visualisations dÃ©taillÃ©es** : Graphiques et analyses en temps rÃ©el  
âœ… **ContrÃ´le total** : AccÃ¨s Ã  tous les paramÃ¨tres et mÃ©triques  
âœ… **ReproductibilitÃ©** : Sauvegarde automatique des configurations  
âœ… **Debugging facile** : Inspection des donnÃ©es Ã  chaque Ã©tape  
âœ… **Rapport automatique** : GÃ©nÃ©ration d'un rapport d'entraÃ®nement complet  

---

## ğŸ“‚ Structure

```
notebooks/
â”œâ”€â”€ README.md                           # Documentation complÃ¨te
â”œâ”€â”€ fine_tune_cross_encoder.ipynb       # Notebook principal â­
â””â”€â”€ (futurs notebooks d'analyse)
```

---

## ğŸš€ DÃ©marrage Rapide (5 minutes)

### 1. Installation

```bash
# Installer Jupyter et les dÃ©pendances
pip install jupyter notebook ipykernel
pip install sentence-transformers torch pymongo pandas matplotlib seaborn scikit-learn
```

### 2. Lancement

```bash
# Se placer dans le rÃ©pertoire notebooks
cd notebooks

# Lancer Jupyter
jupyter notebook
```

Cela ouvrira votre navigateur avec l'interface Jupyter.

### 3. ExÃ©cution

1. Cliquer sur `fine_tune_cross_encoder.ipynb`
2. **ExÃ©cuter toutes les cellules** : Menu â†’ Cell â†’ Run All
3. Attendre la fin de l'entraÃ®nement (~5-15 minutes)
4. Consulter les mÃ©triques et visualisations

### 4. RÃ©sultat

Le notebook gÃ©nÃ¨re :
```
models/cross_encoder_finetuned/
â”œâ”€â”€ config.json                    # Configuration
â”œâ”€â”€ pytorch_model.bin              # ModÃ¨le fine-tunÃ©
â”œâ”€â”€ training_metadata.pkl          # MÃ©tadonnÃ©es
â””â”€â”€ training_report.txt            # Rapport dÃ©taillÃ©
```

### 5. Utilisation

```bash
# RedÃ©marrer l'API (elle chargera automatiquement le modÃ¨le fine-tunÃ©)
python main.py

# Tester
curl -X POST "http://localhost:8000/api/reranking/search-with-reranking" \
  -H "Content-Type: application/json" \
  -d '{"query_text": "machine learning tutorial", "use_reranker": true}'
```

---

## ğŸ“Š Contenu du Notebook

### Section 1 : Configuration
- Imports et vÃ©rifications
- Connexion MongoDB
- Configuration des chemins

### Section 2 : Chargement des DonnÃ©es
- Statistiques des infÃ©rences
- Distribution des feedbacks
- VÃ©rification de la qualitÃ©

### Section 3 : PrÃ©paration
- Extraction des paires (query, document, label)
- CrÃ©ation du DataFrame
- Statistiques descriptives

### Section 4 : Visualisation
- Distribution des labels (like/dislike)
- Longueur des requÃªtes
- Analyse exploratoire

### Section 5 : DataLoaders
- Split train/validation (80/20)
- CrÃ©ation des InputExamples
- Configuration des batchs

### Section 6 : ModÃ¨le de Base
- Chargement du cross-encoder
- VÃ©rification GPU/CPU
- Comptage des paramÃ¨tres

### Section 7 : Configuration
- HyperparamÃ¨tres (epochs, batch_size, learning_rate)
- Calcul des warmup steps
- Affichage du plan d'entraÃ®nement

### Section 8 : Ã‰valuation Baseline
- PrÃ©dictions avant fine-tuning
- Calcul des mÃ©triques (accuracy, F1, AUC)
- Baseline pour comparaison

### Section 9 : Fine-Tuning ğŸš€
- EntraÃ®nement du modÃ¨le
- Barre de progression
- Sauvegarde automatique

### Section 10 : Ã‰valuation Finale
- Rechargement du modÃ¨le fine-tunÃ©
- Nouvelles prÃ©dictions
- Calcul des mÃ©triques amÃ©liorÃ©es

### Section 11 : Comparaison
- Tableau avant/aprÃ¨s
- Calcul des amÃ©liorations
- Pourcentages de gain

### Section 12 : Visualisations
- Graphiques de comparaison
- Distribution des scores
- Matrice de confusion

### Section 13 : Tests
- Exemples de prÃ©dictions
- InterprÃ©tation des scores
- Validation qualitative

### Section 14 : Sauvegarde
- Export des mÃ©tadonnÃ©es
- GÃ©nÃ©ration du rapport
- RÃ©sumÃ© final

---

## ğŸ›ï¸ Configuration

### Variables Principales

```python
# MongoDB
MONGODB_URL = "mongodb://localhost:27017"
MONGODB_DB = "edu_ranker_db"

# ModÃ¨le
BASE_MODEL_NAME = "cross-encoder/ms-marco-MiniLM-L-6-v2"
MODEL_OUTPUT_PATH = "models/cross_encoder_finetuned"

# HyperparamÃ¨tres
NUM_EPOCHS = 3          # Nombre d'Ã©poques (1-10)
BATCH_SIZE = 16         # Taille des batchs (4-64)
LEARNING_RATE = 2e-5    # Taux d'apprentissage
```

### Ajustement des HyperparamÃ¨tres

| ParamÃ¨tre | Par dÃ©faut | Recommandation | Impact |
|-----------|-----------|----------------|--------|
| `NUM_EPOCHS` | 3 | 2-5 | â†‘ = Meilleur apprentissage mais â†‘ temps |
| `BATCH_SIZE` | 16 | 8-32 | â†‘ = Plus rapide mais â†‘ mÃ©moire |
| `LEARNING_RATE` | 2e-5 | 1e-5 Ã  5e-5 | â†‘ = Apprentissage plus rapide mais instable |

**Conseils** :
- **Peu de donnÃ©es (<100)** : RÃ©duire epochs (2-3), augmenter learning_rate (5e-5)
- **Beaucoup de donnÃ©es (>500)** : Augmenter epochs (5-7), garder learning_rate faible (2e-5)
- **MÃ©moire limitÃ©e** : RÃ©duire batch_size (8 ou 4)
- **GPU puissant** : Augmenter batch_size (32 ou 64)

---

## ğŸ“ˆ MÃ©triques Ã‰valuÃ©es

### Accuracy (PrÃ©cision globale)
- **DÃ©finition** : Proportion de prÃ©dictions correctes
- **Formule** : (TP + TN) / (TP + TN + FP + FN)
- **InterprÃ©tation** : 0.8 = 80% de prÃ©dictions correctes

### Precision (PrÃ©cision positive)
- **DÃ©finition** : Proportion de vrais positifs parmi les prÃ©dictions positives
- **Formule** : TP / (TP + FP)
- **InterprÃ©tation** : 0.85 = 85% des "like" prÃ©dits sont corrects

### Recall (Rappel/SensibilitÃ©)
- **DÃ©finition** : Proportion de vrais positifs dÃ©tectÃ©s
- **Formule** : TP / (TP + FN)
- **InterprÃ©tation** : 0.90 = 90% des vrais "like" sont dÃ©tectÃ©s

### F1-Score
- **DÃ©finition** : Moyenne harmonique de precision et recall
- **Formule** : 2 * (precision * recall) / (precision + recall)
- **InterprÃ©tation** : Ã‰quilibre entre precision et recall

### AUC-ROC
- **DÃ©finition** : Aire sous la courbe ROC
- **InterprÃ©tation** : 0.5 = hasard, 1.0 = parfait

---

## ğŸ¯ PrÃ©requis de DonnÃ©es

### Minimum Absolu
- âœ… **10 feedbacks** : Pour tester le notebook
- âš ï¸ Performances limitÃ©es avec si peu de donnÃ©es

### Minimum RecommandÃ©
- âœ… **50-100 feedbacks** : Pour un premier fine-tuning valide
- âœ… Distribution Ã©quilibrÃ©e (50% like, 50% dislike)

### Optimal
- ğŸŒŸ **200-500 feedbacks** : Bonnes performances
- ğŸŒŸ **>500 feedbacks** : Excellentes performances
- ğŸŒŸ **>1000 feedbacks** : Performances maximales

### QualitÃ© des DonnÃ©es
- âœ… Feedbacks de **vrais utilisateurs** (pas de tests)
- âœ… VariÃ©tÃ© de requÃªtes et de ressources
- âœ… Distribution Ã©quilibrÃ©e des labels

---

## âš¡ Performances

### Temps d'ExÃ©cution

| Configuration | 100 exemples | 500 exemples | 1000 exemples |
|--------------|-------------|-------------|---------------|
| **CPU (4 cores)** | 5-8 min | 20-30 min | 40-60 min |
| **GPU (GTX 1060)** | 1-2 min | 5-8 min | 10-15 min |
| **GPU (RTX 3080)** | 30-60 sec | 2-3 min | 4-6 min |

### MÃ©moire Requise

| Composant | Minimum | RecommandÃ© |
|-----------|---------|------------|
| **RAM** | 4 GB | 8 GB |
| **GPU VRAM** | - | 2-4 GB |
| **Disque** | 500 MB | 2 GB |

---

## ğŸ› DÃ©pannage

### Erreur : "Pas assez de feedbacks"

**Cause** : Moins de 10 feedbacks dans la base

**Solution** :
1. Collecter plus de feedbacks via l'API
2. Utiliser l'endpoint de test pour gÃ©nÃ©rer des feedbacks

```bash
# GÃ©nÃ©rer des feedbacks de test
python scripts/test_inference_flow.py
```

### Erreur : "CUDA out of memory"

**Cause** : GPU mÃ©moire insuffisante

**Solution** :
```python
# Dans le notebook, rÃ©duire la taille des batchs
BATCH_SIZE = 8  # ou 4

# OU forcer l'utilisation du CPU
device = "cpu"
```

### Erreur : "Module not found"

**Cause** : DÃ©pendances manquantes

**Solution** :
```bash
pip install sentence-transformers torch pymongo pandas matplotlib seaborn scikit-learn
```

### Le modÃ¨le n'est pas chargÃ© par l'API

**VÃ©rifications** :
1. Le dossier existe : `models/cross_encoder_finetuned/`
2. Il contient `config.json` et `pytorch_model.bin`
3. Les logs de l'API au dÃ©marrage

**Solution** :
```bash
# VÃ©rifier le chemin dans .env
CROSS_ENCODER_PATH=models/cross_encoder_finetuned

# RedÃ©marrer l'API
python main.py

# VÃ©rifier le chargement
curl http://localhost:8000/api/reranking/info-modele
```

---

## ğŸ“Š Workflow Complet

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   WORKFLOW DE FINE-TUNING                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. COLLECTE DES DONNÃ‰ES
   â”œâ”€ Utiliser l'API en production
   â”œâ”€ Collecter feedbacks utilisateurs (like/dislike)
   â””â”€ Objectif : 100+ feedbacks

2. PRÃ‰PARATION
   â”œâ”€ VÃ©rifier MongoDB : db.inference.count()
   â”œâ”€ VÃ©rifier distribution des feedbacks
   â””â”€ S'assurer d'avoir assez de donnÃ©es

3. FINE-TUNING
   â”œâ”€ Lancer Jupyter : jupyter notebook
   â”œâ”€ Ouvrir : fine_tune_cross_encoder.ipynb
   â”œâ”€ Configurer les hyperparamÃ¨tres (si nÃ©cessaire)
   â””â”€ ExÃ©cuter toutes les cellules

4. Ã‰VALUATION
   â”œâ”€ Consulter les mÃ©triques
   â”œâ”€ VÃ©rifier l'amÃ©lioration vs baseline
   â””â”€ Analyser les visualisations

5. VALIDATION
   â”œâ”€ Tester sur nouveaux exemples
   â”œâ”€ VÃ©rifier la matrice de confusion
   â””â”€ S'assurer que les performances sont satisfaisantes

6. DÃ‰PLOIEMENT
   â”œâ”€ RedÃ©marrer l'API : python main.py
   â”œâ”€ VÃ©rifier le chargement du modÃ¨le
   â””â”€ Tester via l'API

7. MONITORING
   â”œâ”€ Suivre les nouvelles mÃ©triques
   â”œâ”€ Collecter plus de feedbacks
   â””â”€ Planifier le prochain rÃ©entraÃ®nement

8. CYCLE D'AMÃ‰LIORATION CONTINUE
   â””â”€ RÃ©pÃ©ter tous les 1-3 mois ou aprÃ¨s 100+ nouveaux feedbacks
```

---

## ğŸ”— API vs Notebook

### Ancienne MÃ©thode (API) âŒ

```bash
curl -X POST "http://localhost:8000/api/reranking/fine-tune?num_epochs=3"
```

**Limitations** :
- âŒ Pas de visualisations
- âŒ MÃ©triques limitÃ©es
- âŒ Pas de rapport dÃ©taillÃ©
- âŒ Difficile Ã  debugger
- âŒ Pas de contrÃ´le intermÃ©diaire

### Nouvelle MÃ©thode (Notebook) âœ…

```bash
cd notebooks
jupyter notebook
# Ouvrir fine_tune_cross_encoder.ipynb
```

**Avantages** :
- âœ… Visualisations riches (graphiques, distributions)
- âœ… MÃ©triques complÃ¨tes (accuracy, F1, AUC, confusion matrix)
- âœ… Rapport automatique sauvegardÃ©
- âœ… Debugging facile (inspection des donnÃ©es)
- âœ… ContrÃ´le total (modifier code, paramÃ¨tres)
- âœ… ReproductibilitÃ© (configuration sauvegardÃ©e)

---

## ğŸ“š Ressources

### Documentation
- **Notebook README** : `notebooks/README.md`
- **Inference Tracking** : `docs/INFERENCE_TRACKING.md`
- **API Documentation** : http://localhost:8000/docs

### Liens Externes
- **Sentence-Transformers** : https://www.sbert.net/
- **Cross-Encoder Tutorial** : https://www.sbert.net/examples/applications/cross-encoder/
- **Jupyter Documentation** : https://jupyter.org/documentation

---

## âœ… Checklist de Fine-Tuning

Avant de lancer le fine-tuning :

- [ ] MongoDB accessible et contient des donnÃ©es
- [ ] Au moins 50+ feedbacks collectÃ©s (100+ recommandÃ©)
- [ ] Distribution Ã©quilibrÃ©e (â‰ˆ50% like, â‰ˆ50% dislike)
- [ ] Jupyter installÃ© : `pip install jupyter notebook`
- [ ] DÃ©pendances installÃ©es : `pip install sentence-transformers torch ...`
- [ ] GPU disponible (recommandÃ© mais optionnel)

Pendant le fine-tuning :

- [ ] Surveiller les mÃ©triques (pas de surapprentissage)
- [ ] VÃ©rifier les visualisations
- [ ] S'assurer que l'amÃ©lioration est significative

AprÃ¨s le fine-tuning :

- [ ] ModÃ¨le sauvegardÃ© dans `models/cross_encoder_finetuned/`
- [ ] Rapport gÃ©nÃ©rÃ© : `training_report.txt`
- [ ] API redÃ©marrÃ©e
- [ ] ModÃ¨le chargÃ© (vÃ©rifier les logs)
- [ ] Tests effectuÃ©s

---

## ğŸ‰ Conclusion

Le fine-tuning via Jupyter Notebook offre une **expÃ©rience complÃ¨te et professionnelle** pour amÃ©liorer votre modÃ¨le de reranking.

**Prochaine Ã©tape** : Lancez le notebook et commencez Ã  amÃ©liorer votre systÃ¨me ! ğŸš€

```bash
cd notebooks
jupyter notebook
# Ouvrir fine_tune_cross_encoder.ipynb et exÃ©cuter !
```

---

**CrÃ©Ã© le** : 8 dÃ©cembre 2024  
**Version** : 1.0  
**Auteur** : EduRanker Development Team
