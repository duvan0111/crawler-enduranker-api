# ðŸ““ Notebooks - Fine-Tuning et Analyse

Ce rÃ©pertoire contient les Jupyter Notebooks pour le fine-tuning et l'analyse du systÃ¨me EduRanker.

## ðŸ“‹ Notebooks Disponibles

### `fine_tune_cross_encoder.ipynb` â­

**Notebook principal pour fine-tuner le modÃ¨le cross-encoder.**

#### ðŸŽ¯ Objectif
Fine-tuner le modÃ¨le cross-encoder sur les feedbacks utilisateurs collectÃ©s pour amÃ©liorer la qualitÃ© du reranking.

#### ðŸ“Š Contenu
1. **Configuration** : Connexion MongoDB, paramÃ¨tres du modÃ¨le
2. **Chargement des donnÃ©es** : RÃ©cupÃ©ration des feedbacks depuis MongoDB
3. **PrÃ©paration** : CrÃ©ation des paires d'entraÃ®nement (query, document, label)
4. **Visualisation** : Analyse exploratoire des donnÃ©es
5. **Fine-tuning** : EntraÃ®nement du modÃ¨le avec sentence-transformers
6. **Ã‰valuation** : MÃ©triques de performance (accuracy, F1, AUC)
7. **Comparaison** : Avant/aprÃ¨s fine-tuning
8. **Sauvegarde** : Export du modÃ¨le et des mÃ©tadonnÃ©es

#### ðŸš€ Utilisation

**1. PrÃ©requis**
```bash
# Installer Jupyter
pip install jupyter notebook ipykernel

# Installer les dÃ©pendances
pip install sentence-transformers torch pymongo pandas matplotlib seaborn scikit-learn
```

**2. Lancer Jupyter**
```bash
cd notebooks
jupyter notebook
```

**3. Ouvrir le notebook**
- Ouvrir `fine_tune_cross_encoder.ipynb`
- ExÃ©cuter les cellules dans l'ordre (Shift+Enter)

**4. Configuration**
Modifier les variables si nÃ©cessaire :
```python
MONGODB_URL = "mongodb://localhost:27017"  # URL MongoDB
MONGODB_DB = "edu_ranker_db"                # Nom de la base
BASE_MODEL_NAME = "cross-encoder/ms-marco-MiniLM-L-6-v2"  # ModÃ¨le de base
MODEL_OUTPUT_PATH = "models/cross_encoder_finetuned"      # Dossier de sortie
```

**5. HyperparamÃ¨tres**
Ajustables selon vos besoins :
```python
NUM_EPOCHS = 3          # Nombre d'Ã©poques (1-10)
BATCH_SIZE = 16         # Taille des batchs (4-64)
LEARNING_RATE = 2e-5    # Taux d'apprentissage
```

#### ðŸ“¦ Sorties GÃ©nÃ©rÃ©es

AprÃ¨s exÃ©cution, le notebook gÃ©nÃ¨re :
```
models/cross_encoder_finetuned/
â”œâ”€â”€ config.json                    # Configuration du modÃ¨le
â”œâ”€â”€ pytorch_model.bin              # Poids du modÃ¨le fine-tunÃ©
â”œâ”€â”€ training_metadata.pkl          # MÃ©tadonnÃ©es d'entraÃ®nement
â””â”€â”€ training_report.txt            # Rapport dÃ©taillÃ©
```

#### ðŸ“ˆ MÃ©triques Ã‰valuÃ©es

- **Accuracy** : PrÃ©cision globale
- **Precision** : PrÃ©cision des prÃ©dictions positives
- **Recall** : Rappel (sensibilitÃ©)
- **F1-Score** : Moyenne harmonique de precision/recall
- **AUC-ROC** : Aire sous la courbe ROC

#### âš™ï¸ Fonctionnement

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PIPELINE DE FINE-TUNING                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. CHARGEMENT DES DONNÃ‰ES
   â”œâ”€ Connexion MongoDB
   â”œâ”€ RÃ©cupÃ©ration infÃ©rences avec feedback
   â””â”€ Jointure avec user_queries et resources

2. PRÃ‰PARATION
   â”œâ”€ Extraction (query_text, document_text, label)
   â”œâ”€ Label : 1.0 (like) ou 0.0 (dislike)
   â””â”€ Split train/val (80/20)

3. FINE-TUNING
   â”œâ”€ Chargement modÃ¨le de base
   â”œâ”€ Configuration optimiseur (Adam)
   â”œâ”€ EntraÃ®nement (3 epochs par dÃ©faut)
   â””â”€ Sauvegarde automatique

4. Ã‰VALUATION
   â”œâ”€ PrÃ©dictions sur validation
   â”œâ”€ Calcul des mÃ©triques
   â””â”€ Comparaison avant/aprÃ¨s

5. SAUVEGARDE
   â”œâ”€ ModÃ¨le fine-tunÃ©
   â”œâ”€ MÃ©tadonnÃ©es
   â””â”€ Rapport d'entraÃ®nement
```

#### ðŸŽ¯ PrÃ©requis de DonnÃ©es

**Minimum recommandÃ©** :
- âœ… Au moins **50 feedbacks** (like/dislike)
- âœ… Distribution Ã©quilibrÃ©e (50% like, 50% dislike)
- âœ… Feedbacks de qualitÃ© (vrais utilisateurs)

**Pour de meilleures performances** :
- ðŸŒŸ **100-500 feedbacks** : Bon
- ðŸŒŸ **500-1000 feedbacks** : TrÃ¨s bon
- ðŸŒŸ **>1000 feedbacks** : Excellent

#### ðŸ“Š Visualisations

Le notebook gÃ©nÃ¨re plusieurs graphiques :
1. **Distribution des labels** : RÃ©partition like/dislike
2. **Longueur des requÃªtes** : Histogramme
3. **Comparaison des performances** : Avant/aprÃ¨s
4. **Distribution des scores** : PrÃ©dictions du modÃ¨le
5. **Matrice de confusion** : Analyse des erreurs

#### âš ï¸ Notes Importantes

1. **GPU recommandÃ©** : Le fine-tuning est plus rapide sur GPU (CUDA)
   - CPU : ~5-15 minutes pour 100 exemples
   - GPU : ~1-3 minutes pour 100 exemples

2. **MÃ©moire** :
   - RAM : Minimum 4GB
   - GPU : Minimum 2GB VRAM

3. **DurÃ©e** :
   - DÃ©pend du nombre d'exemples et d'epochs
   - ~1 minute par epoch pour 100 exemples (GPU)

4. **RÃ©entraÃ®nement** :
   - Relancer le notebook pÃ©riodiquement
   - RecommandÃ© aprÃ¨s 100+ nouveaux feedbacks

#### ðŸ”§ DÃ©pannage

**Erreur : "Pas assez de feedbacks"**
- Collecter plus de feedbacks via l'API
- Minimum : 10 feedbacks (test), 50+ (recommandÃ©)

**Erreur : "CUDA out of memory"**
- RÃ©duire `BATCH_SIZE` (ex: 8 ou 4)
- Utiliser CPU : `device = "cpu"`

**Erreur : "Module not found"**
```bash
pip install sentence-transformers torch pymongo pandas matplotlib seaborn scikit-learn
```

**ModÃ¨le pas chargÃ© dans l'API**
- VÃ©rifier que le dossier existe : `models/cross_encoder_finetuned/`
- VÃ©rifier les logs au dÃ©marrage de l'API
- Chemin configurÃ© dans `.env` : `CROSS_ENCODER_PATH=models/cross_encoder_finetuned`

#### ðŸš€ IntÃ©gration avec l'API

AprÃ¨s le fine-tuning, le modÃ¨le est automatiquement utilisÃ© par l'API :

1. **RedÃ©marrer l'API** :
```bash
python main.py
```

2. **VÃ©rifier le chargement** :
```bash
curl http://localhost:8000/api/reranking/info-modele
```

3. **Tester** :
```bash
curl -X POST "http://localhost:8000/api/reranking/search-with-reranking" \
  -H "Content-Type: application/json" \
  -d '{"query_text": "machine learning tutorial", "use_reranker": true}'
```

#### ðŸ“ˆ Workflow RecommandÃ©

```
1. Collecter des feedbacks
   â””â”€> Utiliser l'API en production
   â””â”€> Objectif : 100+ feedbacks

2. Fine-tuner le modÃ¨le
   â””â”€> ExÃ©cuter ce notebook
   â””â”€> VÃ©rifier les mÃ©triques

3. DÃ©ployer
   â””â”€> RedÃ©marrer l'API
   â””â”€> Tester les performances

4. Monitorer
   â””â”€> Suivre les nouvelles mÃ©triques
   â””â”€> Collecter plus de feedbacks

5. RÃ©pÃ©ter (cycle d'amÃ©lioration continue)
   â””â”€> RÃ©entraÃ®ner tous les mois
   â””â”€> Ou aprÃ¨s 100+ nouveaux feedbacks
```

#### ðŸ“š Ressources

- **Sentence-Transformers** : https://www.sbert.net/
- **Cross-Encoder** : https://www.sbert.net/examples/applications/cross-encoder/README.html
- **Documentation API** : http://localhost:8000/docs

---

## ðŸŽ¯ Prochains Notebooks (Ã€ venir)

- `analyze_performance.ipynb` : Analyse des performances du systÃ¨me
- `data_exploration.ipynb` : Exploration des donnÃ©es collectÃ©es
- `ab_testing.ipynb` : Comparaison de diffÃ©rents modÃ¨les
- `user_behavior.ipynb` : Analyse du comportement utilisateur

---

## ðŸ“ž Support

Pour toute question ou problÃ¨me :
1. VÃ©rifier la documentation : `docs/INFERENCE_TRACKING.md`
2. Consulter les logs de l'API
3. Tester avec des exemples simples

---

**CrÃ©Ã© le** : 8 dÃ©cembre 2024  
**Version** : 1.0  
**Auteur** : EduRanker Development Team
