"""
Service pour le workflow global de traitement des requ√™tes utilisateur.
Orchestre le crawling, la recherche s√©mantique et le re-ranking.
"""

import logging
import time
from typing import List, Dict, Optional
from datetime import datetime

from src.services.crawler_service import get_simple_crawler_service
from src.services.user_query_service import get_user_query_service_simple
from src.services.nlp_service import get_nlp_service
from src.services.reranking_service import get_reranking_service
from src.models.workflow_model import (
    WorkflowRequestModel,
    WorkflowResponseModel,
    RessourceResultatModel
)

logger = logging.getLogger(__name__)


class WorkflowService:
    """Service pour orchestrer le workflow complet de traitement"""
    
    def __init__(
        self,
        mongodb_url: str,
        mongodb_db: str,
        index_path: str = "data/faiss_index"
    ):
        """
        Initialise le service de workflow
        
        Args:
            mongodb_url: URL de connexion MongoDB
            mongodb_db: Nom de la base de donn√©es
            index_path: Chemin de l'index FAISS
        """
        self.mongodb_url = mongodb_url
        self.mongodb_db = mongodb_db
        self.index_path = index_path
        
        # Initialiser les services n√©cessaires
        logger.info("üîß Initialisation des services du workflow...")
        
        self.crawler_service = get_simple_crawler_service(mongodb_url, mongodb_db)
        self.user_query_service = get_user_query_service_simple(mongodb_url, mongodb_db)
        self.nlp_service = get_nlp_service(mongodb_url, mongodb_db, index_path)
        self.reranking_service = get_reranking_service(mongodb_url, mongodb_db)
        
        logger.info("‚úÖ Services du workflow initialis√©s")
    
    async def traiter_requete_complete(
        self,
        request: WorkflowRequestModel
    ) -> WorkflowResponseModel:
        """
        Traite une requ√™te utilisateur de bout en bout
        
        Workflow:
        1. Sauvegarder la question de l'utilisateur
        2. Lancer le crawling sur les sources demand√©es
        3. Reconstruire l'index FAISS avec les nouvelles donn√©es
        4. Effectuer la recherche s√©mantique avec FAISS
        5. Re-ranker les r√©sultats avec le cross-encoder
        6. Sauvegarder les inf√©rences
        7. Retourner le top 10 des meilleures ressources
        
        Args:
            request: Param√®tres de la requ√™te
            
        Returns:
            R√©sultats du workflow complet
        """
        temps_debut_total = time.time()
        erreurs = []
        
        logger.info(f"üöÄ D√©but du workflow pour la question: {request.question}")
        
        try:
            # ============================================================
            # √âTAPE 1: Sauvegarder la question de l'utilisateur
            # ============================================================
            logger.info("üìù √âTAPE 1/6: Sauvegarde de la question utilisateur...")
            temps_debut_etape = time.time()
            
            try:
                requete_sauvegardee = await self.user_query_service.sauvegarder_requete_async(
                    request.question
                )
                id_requete = requete_sauvegardee["id"]
                logger.info(f"‚úÖ Question sauvegard√©e (ID: {id_requete})")
            except Exception as e:
                logger.error(f"‚ùå Erreur sauvegarde question: {e}")
                erreurs.append(f"Erreur sauvegarde question: {str(e)}")
                id_requete = "non_sauvegarde"
            
            # ============================================================
            # √âTAPE 2: Lancer le crawling
            # ============================================================
            logger.info("üï∑Ô∏è  √âTAPE 2/6: Lancement du crawling...")
            temps_debut_crawl = time.time()
            
            try:
                resultats_crawl = await self.crawler_service.rechercher_ressources_async(
                    requete=request.question,
                    max_par_site=request.max_par_site,
                    sources=request.sources,
                    langues=request.langues
                )
                
                duree_crawl = time.time() - temps_debut_crawl
                total_crawle = resultats_crawl.get("total_collecte", 0)
                sources_crawlees = resultats_crawl.get("sources_utilisees", [])
                
                logger.info(f"‚úÖ Crawling termin√©: {total_crawle} ressources en {duree_crawl:.2f}s")
                
                # Ajouter les erreurs du crawling
                if resultats_crawl.get("erreurs"):
                    erreurs.extend(resultats_crawl["erreurs"])
                
            except Exception as e:
                logger.error(f"‚ùå Erreur crawling: {e}")
                erreurs.append(f"Erreur crawling: {str(e)}")
                duree_crawl = 0
                total_crawle = 0
                sources_crawlees = []
            
            # ============================================================
            # √âTAPE 3: Reconstruire l'index FAISS
            # ============================================================
            logger.info("üîÑ √âTAPE 3/6: Reconstruction de l'index FAISS...")
            temps_debut_index = time.time()
            
            try:
                resultat_index = await self.nlp_service.reconstruire_index_depuis_bd()
                logger.info(f"‚úÖ Index FAISS reconstruit: {resultat_index.get('total_vecteurs', 0)} vecteurs")
            except Exception as e:
                logger.error(f"‚ùå Erreur reconstruction index: {e}")
                erreurs.append(f"Erreur reconstruction index: {str(e)}")
            
            # ============================================================
            # √âTAPE 4: Recherche s√©mantique avec FAISS
            # ============================================================
            logger.info("üîç √âTAPE 4/6: Recherche s√©mantique avec FAISS...")
            temps_debut_recherche = time.time()
            
            try:
                resultats_faiss = await self.nlp_service.rechercher_ressources_similaires(
                    question=request.question,
                    top_k=request.top_k_faiss
                )
                
                duree_recherche = time.time() - temps_debut_recherche
                total_resultats_faiss = len(resultats_faiss)
                
                logger.info(f"‚úÖ Recherche FAISS: {total_resultats_faiss} r√©sultats en {duree_recherche:.2f}s")
                
            except Exception as e:
                logger.error(f"‚ùå Erreur recherche FAISS: {e}")
                erreurs.append(f"Erreur recherche FAISS: {str(e)}")
                resultats_faiss = []
                duree_recherche = 0
                total_resultats_faiss = 0
            
            # ============================================================
            # √âTAPE 5: Re-ranking avec cross-encoder
            # ============================================================
            logger.info("üéØ √âTAPE 5/6: Re-ranking avec cross-encoder...")
            temps_debut_reranking = time.time()
            
            try:
                resultats_rerankes = await self.reranking_service.reranker_resultats(
                    question=request.question,
                    resultats_faiss=resultats_faiss,
                    top_k=request.top_k_final
                )
                
                duree_reranking = time.time() - temps_debut_reranking
                logger.info(f"‚úÖ Re-ranking termin√©: {len(resultats_rerankes)} r√©sultats en {duree_reranking:.2f}s")
                
            except Exception as e:
                logger.error(f"‚ùå Erreur re-ranking: {e}")
                erreurs.append(f"Erreur re-ranking: {str(e)}")
                resultats_rerankes = resultats_faiss[:request.top_k_final]
                duree_reranking = 0
            
            # ============================================================
            # √âTAPE 6: Sauvegarder les inf√©rences et formater les r√©sultats
            # ============================================================
            logger.info("üíæ √âTAPE 6/6: Sauvegarde des inf√©rences...")
            
            resultats_finaux = []
            
            for idx, resultat in enumerate(resultats_rerankes):
                try:
                    # Calculer le score final (moyenne pond√©r√©e)
                    score_faiss = resultat.get("score_faiss", 0.0)
                    score_reranking = resultat.get("score_reranking", 0.0)
                    score_final = (0.3 * score_faiss + 0.7 * score_reranking) if score_reranking else score_faiss
                    
                    # Sauvegarder l'inf√©rence dans MongoDB
                    inference_result = await self.reranking_service.sauvegarder_inference(
                        user_query_id=id_requete,
                        resource_id=str(resultat.get("_id", resultat.get("id", ""))),
                        faiss_score=score_faiss,
                        reranking_score=score_reranking,
                        final_score=score_final,
                        rank=idx + 1
                    )
                    
                    id_inference = inference_result.get("inference_id", "unknown")
                    
                    # Formater le r√©sultat
                    ressource_formatee = RessourceResultatModel(
                        titre=resultat.get("titre", "Sans titre"),
                        url=resultat.get("url", ""),
                        auteur=resultat.get("auteur"),
                        date=resultat.get("date"),
                        resume=resultat.get("resume"),
                        score_faiss=score_faiss,
                        score_reranking=score_reranking,
                        score_final=score_final,
                        mots_cles=resultat.get("mots_cles", []),
                        source=resultat.get("source", "inconnu"),
                        id_inference=id_inference
                    )
                    
                    resultats_finaux.append(ressource_formatee)
                    
                except Exception as e:
                    logger.error(f"‚ùå Erreur sauvegarde inf√©rence pour r√©sultat {idx}: {e}")
                    erreurs.append(f"Erreur sauvegarde inf√©rence: {str(e)}")
            
            # ============================================================
            # Pr√©parer la r√©ponse finale
            # ============================================================
            duree_totale = time.time() - temps_debut_total
            
            logger.info(f"‚úÖ Workflow termin√© en {duree_totale:.2f}s")
            logger.info(f"üìä R√©sultats: {len(resultats_finaux)} ressources finales")
            
            reponse = WorkflowResponseModel(
                question=request.question,
                id_requete=id_requete,
                total_crawle=total_crawle,
                total_resultats_faiss=total_resultats_faiss,
                total_resultats_final=len(resultats_finaux),
                duree_crawl_secondes=round(duree_crawl, 2),
                duree_recherche_secondes=round(duree_recherche, 3),
                duree_reranking_secondes=round(duree_reranking, 2),
                duree_totale_secondes=round(duree_totale, 2),
                resultats=resultats_finaux,
                sources_crawlees=sources_crawlees,
                erreurs=erreurs if erreurs else None
            )
            
            return reponse
            
        except Exception as e:
            logger.error(f"‚ùå Erreur critique dans le workflow: {e}")
            raise


# Singleton pour le service de workflow
_workflow_service_instance = None


def get_workflow_service(
    mongodb_url: str,
    mongodb_db: str,
    index_path: str = "data/faiss_index"
) -> WorkflowService:
    """
    Retourne une instance singleton du service de workflow
    
    Args:
        mongodb_url: URL de connexion MongoDB
        mongodb_db: Nom de la base de donn√©es
        index_path: Chemin de l'index FAISS
        
    Returns:
        Instance du WorkflowService
    """
    global _workflow_service_instance
    
    if _workflow_service_instance is None:
        _workflow_service_instance = WorkflowService(
            mongodb_url=mongodb_url,
            mongodb_db=mongodb_db,
            index_path=index_path
        )
    
    return _workflow_service_instance
