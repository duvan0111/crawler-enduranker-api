# ğŸ“ EduRanker - API Backend Intelligente

> **SystÃ¨me de recommandation de ressources Ã©ducatives avec IA**
> 
> Backend FastAPI avancÃ© combinant crawling intelligent, recherche sÃ©mantique FAISS, et re-ranking par deep learning pour fournir les meilleures ressources Ã©ducatives.

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![MongoDB](https://img.shields.io/badge/MongoDB-6.0+-green.svg)](https://www.mongodb.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

## ğŸ“‹ Table des MatiÃ¨res

- [Vue d'Ensemble](#-vue-densemble)
- [FonctionnalitÃ©s Principales](#-fonctionnalitÃ©s-principales)
- [Architecture](#-architecture)
- [Workflow Global](#-workflow-global)
- [Installation](#-installation)
- [Utilisation](#-utilisation)
- [API Endpoints](#-api-endpoints)
- [Technologies](#-technologies)
- [Documentation](#-documentation)
- [Tests](#-tests)
- [Performances](#-performances)
- [Contributing](#-contributing)

---

## ğŸŒŸ Vue d'Ensemble

**EduRanker** est une API backend intelligente qui permet de dÃ©couvrir, analyser et classer automatiquement les meilleures ressources Ã©ducatives sur le web. Le systÃ¨me utilise des techniques avancÃ©es de NLP et de Machine Learning pour comprendre les questions des utilisateurs et leur fournir les ressources les plus pertinentes.

### ğŸ¯ Objectifs du Projet

- **Automatiser** la recherche de ressources Ã©ducatives de qualitÃ©
- **Classifier** intelligemment les ressources par pertinence
- **Apprendre** continuellement des interactions utilisateurs
- **Fournir** des recommandations personnalisÃ©es et prÃ©cises

### ğŸš€ Cas d'Usage

- **Plateformes e-learning** : Recommandation de cours et tutoriels
- **Assistants Ã©ducatifs** : RÃ©ponses contextuelles avec ressources
- **Moteurs de recherche acadÃ©miques** : Classement intelligent
- **SystÃ¨mes de gestion des connaissances** : Curation automatique

---

## âœ¨ FonctionnalitÃ©s Principales

### ğŸ”¥ Workflow Global (All-in-One)

Le **workflow global** est la fonctionnalitÃ© phare qui traite une requÃªte de bout en bout :

```bash
Question â†’ Crawling â†’ Recherche SÃ©mantique â†’ Re-ranking â†’ Top 10 RÃ©sultats
```

**Une seule requÃªte API pour tout obtenir !**

```bash
curl -X POST "http://localhost:8000/api/workflow/process" \
  -H "Content-Type: application/json" \
  -d '{"question": "Comment apprendre le machine learning ?"}'
```

â¡ï¸ **[Guide Complet du Workflow](docs/WORKFLOW_GUIDE.md)**

### ğŸ•·ï¸ Crawler Multi-Sources Intelligent

- **Wikipedia** : Articles Ã©ducatifs multilingues (FR/EN)
- **GitHub** : Repositories, README, documentation
- **YouTube** : VidÃ©os Ã©ducatives via API officielle (gratuit, 10k requÃªtes/jour) ğŸ†•
- **Medium** : Articles de blog et tutoriels
- **GÃ©nÃ©ration automatique d'embeddings** (384 dimensions)
- **Extraction de mÃ©tadonnÃ©es** : auteur, date, mots-clÃ©s, popularitÃ©

â¡ï¸ **[Guide YouTube Integration](docs/YOUTUBE_INTEGRATION.md)**

### ğŸ” Recherche SÃ©mantique FAISS

- **Index vectoriel FAISS** pour recherche ultra-rapide
- **Sentence-Transformers** (all-MiniLM-L6-v2)
- **SimilaritÃ© cosine** pour matching sÃ©mantique
- **Scalable** : GÃ¨re des millions de ressources
- **Persistance** : Sauvegarde/chargement de l'index

### ğŸ¯ Re-ranking avec Cross-Encoder

- **ModÃ¨le BERT** (ms-marco-MiniLM-L-6-v2)
- **Ã‰valuation fine** de la pertinence
- **Fine-tuning** avec feedbacks utilisateurs
- **AmÃ©lioration continue** des performances

### ğŸ’¾ SystÃ¨me d'InfÃ©rence et Feedback

- **Tracking automatique** de toutes les recommandations
- **Feedback simplifiÃ©** : like/dislike/click/view
- **Collection MongoDB** dÃ©diÃ©e avec indexation
- **Analyse de performance** et mÃ©triques
- **PrÃ©paration fine-tuning** automatique

### ğŸ“Š API REST ComplÃ¨te

- **FastAPI** avec documentation interactive
- **Architecture MVC** propre et maintenable
- **Validation Pydantic** des donnÃ©es
- **Gestion d'erreurs** robuste
- **CORS configurÃ©** pour intÃ©gration frontend

---

## ğŸ—ï¸ Architecture

### Architecture Globale

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CLIENT (Frontend)                         â”‚
â”‚                  Web App / Mobile App / API Client               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ HTTP/REST
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FASTAPI APPLICATION                         â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚   Routes     â”‚  â”‚ Controllers  â”‚  â”‚   Services    â”‚        â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚               â”‚        â”‚
â”‚  â”‚ - Workflow   â”‚â”€â”€â”‚ - Workflow   â”‚â”€â”€â”‚ - Workflow    â”‚        â”‚
â”‚  â”‚ - Crawler    â”‚  â”‚ - Crawler    â”‚  â”‚ - Crawler     â”‚        â”‚
â”‚  â”‚ - NLP        â”‚  â”‚ - NLP        â”‚  â”‚ - NLP         â”‚        â”‚
â”‚  â”‚ - Reranking  â”‚  â”‚ - Reranking  â”‚  â”‚ - Reranking   â”‚        â”‚
â”‚  â”‚ - Queries    â”‚  â”‚ - Queries    â”‚  â”‚ - Queries     â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                           â”‚
               â–¼                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      MONGODB             â”‚  â”‚    FAISS INDEX (Local)         â”‚
â”‚                          â”‚  â”‚                                â”‚
â”‚ Collections:             â”‚  â”‚ - Vector embeddings            â”‚
â”‚ - ressources_educatives  â”‚  â”‚ - Fast similarity search       â”‚
â”‚ - users_queries          â”‚  â”‚ - Persisted on disk            â”‚
â”‚ - inference              â”‚  â”‚                                â”‚
â”‚ - user_feedbacks         â”‚  â”‚                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Architecture MVC

```
src/
â”œâ”€â”€ routes/              # DÃ©finition des endpoints API
â”‚   â”œâ”€â”€ workflow_routes.py      # Route principale du workflow
â”‚   â”œâ”€â”€ crawler_routes.py       # Routes de crawling
â”‚   â”œâ”€â”€ nlp_routes.py           # Routes NLP/FAISS
â”‚   â””â”€â”€ reranking_routes.py     # Routes re-ranking
â”‚
â”œâ”€â”€ controllers/         # Logique de contrÃ´le HTTP
â”‚   â”œâ”€â”€ workflow_controller.py
â”‚   â”œâ”€â”€ crawler_controller.py
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ services/            # Logique mÃ©tier
â”‚   â”œâ”€â”€ workflow_service.py     # Orchestration globale
â”‚   â”œâ”€â”€ crawler_service.py      # Crawling multi-sources
â”‚   â”œâ”€â”€ nlp_service.py          # FAISS + embeddings
â”‚   â”œâ”€â”€ reranking_service.py    # Cross-encoder
â”‚   â””â”€â”€ user_query_service.py   # Gestion requÃªtes
â”‚
â””â”€â”€ models/              # ModÃ¨les Pydantic
    â”œâ”€â”€ workflow_model.py
    â”œâ”€â”€ crawler_model.py
    â””â”€â”€ ...
```

---

## ğŸ”„ Workflow Global

### Vue d'Ensemble

Le **workflow global** est le cÅ“ur de l'application. Il orchestre 6 Ã©tapes pour transformer une question en liste de ressources classÃ©es.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Question: "Comment apprendre le machine learning ?"   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ 1ï¸âƒ£ SAUVEGARDE QUESTION  â”‚
        â”‚                         â”‚
        â”‚ â€¢ Stockage MongoDB      â”‚
        â”‚ â€¢ GÃ©nÃ©ration embedding  â”‚
        â”‚ â€¢ DÃ©tection langue      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ 2ï¸âƒ£ CRAWLING SOURCES     â”‚
        â”‚                         â”‚
        â”‚ â€¢ Wikipedia (FR/EN)     â”‚
        â”‚ â€¢ GitHub Repos          â”‚
        â”‚ â€¢ Medium Articles       â”‚
        â”‚ â€¢ Extraction mÃ©tadonnÃ©esâ”‚
        â”‚ â€¢ GÃ©nÃ©ration embeddings â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ 3ï¸âƒ£ INDEX FAISS          â”‚
        â”‚                         â”‚
        â”‚ â€¢ Chargement embeddings â”‚
        â”‚ â€¢ Construction index    â”‚
        â”‚ â€¢ Sauvegarde disque     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ 4ï¸âƒ£ RECHERCHE SEMANTIQUE â”‚
        â”‚                         â”‚
        â”‚ â€¢ Embedding question    â”‚
        â”‚ â€¢ SimilaritÃ© cosine     â”‚
        â”‚ â€¢ Top 50 rÃ©sultats      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ 5ï¸âƒ£ RE-RANKING           â”‚
        â”‚                         â”‚
        â”‚ â€¢ Cross-Encoder BERT    â”‚
        â”‚ â€¢ Ã‰valuation fine       â”‚
        â”‚ â€¢ Top 10 finaux         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ 6ï¸âƒ£ SAUVEGARDE INFERENCESâ”‚
        â”‚                         â”‚
        â”‚ â€¢ Tracking recommandations â”‚
        â”‚ â€¢ PrÃªt pour feedbacks   â”‚
        â”‚ â€¢ MÃ©triques performance â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   TOP 10 RESSOURCES     â”‚
        â”‚                         â”‚
        â”‚ â€¢ Titre, URL, Auteur    â”‚
        â”‚ â€¢ Scores dÃ©taillÃ©s      â”‚
        â”‚ â€¢ Mots-clÃ©s, Source     â”‚
        â”‚ â€¢ ID infÃ©rence          â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Utilisation du Workflow

**RequÃªte minimale :**
```bash
curl -X POST "http://localhost:8000/api/workflow/process" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Comment apprendre Python ?"
  }'
```

**RequÃªte complÃ¨te avec paramÃ¨tres :**
```bash
curl -X POST "http://localhost:8000/api/workflow/process" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Deep learning tutorial",
    "max_par_site": 20,
    "sources": ["wikipedia", "github", "medium"],
    "langues": ["fr", "en"],
    "top_k_faiss": 50,
    "top_k_final": 10
  }'
```

**Exemple Python :**
```python
import requests

response = requests.post(
    "http://localhost:8000/api/workflow/process",
    json={"question": "Comment utiliser TensorFlow ?"}
)

data = response.json()
print(f"âœ… {data['total_resultats_final']} rÃ©sultats en {data['duree_totale_secondes']}s")

for i, r in enumerate(data['resultats'], 1):
    print(f"{i}. {r['titre']} (score: {r['score_final']:.2f})")
    print(f"   {r['url']}")
```

### Format de RÃ©ponse

```json
{
  "question": "Comment apprendre le machine learning ?",
  "id_requete": "507f1f77bcf86cd799439011",
  "total_crawle": 45,
  "total_resultats_faiss": 50,
  "total_resultats_final": 10,
  "duree_crawl_secondes": 12.5,
  "duree_recherche_secondes": 0.3,
  "duree_reranking_secondes": 1.2,
  "duree_totale_secondes": 14.0,
  "resultats": [
    {
      "titre": "Introduction au Machine Learning",
      "url": "https://fr.wikipedia.org/wiki/Machine_learning",
      "auteur": "Wikipedia Contributors",
      "date": "2024-01-15",
      "score_faiss": 0.85,
      "score_reranking": 0.92,
      "score_final": 0.89,
      "mots_cles": ["machine learning", "IA", "apprentissage"],
      "source": "wikipedia",
      "id_inference": "507f1f77bcf86cd799439012"
    }
    // ... 9 autres ressources
  ],
  "sources_crawlees": ["wikipedia", "github", "medium"],
  "erreurs": []
}
```

â¡ï¸ **[Documentation complÃ¨te du workflow](docs/WORKFLOW_GUIDE.md)**

---

## ğŸ“ Structure du Projet

```
crawler-enduranker-api/
â”œâ”€â”€ ğŸ“„ main.py                          # Point d'entrÃ©e de l'application
â”œâ”€â”€ ğŸ“„ requirements.txt                 # DÃ©pendances Python
â”œâ”€â”€ ğŸ“„ docker-compose.yml               # Configuration Docker (MongoDB)
â”œâ”€â”€ ğŸ“„ .env                            # Variables d'environnement
â”‚
â”œâ”€â”€ ğŸ“ src/                            # Code source principal
â”‚   â”œâ”€â”€ database.py                    # Configuration MongoDB
â”‚   â”œâ”€â”€ utils.py                       # Utilitaires communs
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ routes/                     # Endpoints API (FastAPI)
â”‚   â”‚   â”œâ”€â”€ workflow_routes.py         # ğŸ”¥ Route principale du workflow
â”‚   â”‚   â”œâ”€â”€ crawler_routes.py          # Routes de crawling
â”‚   â”‚   â”œâ”€â”€ nlp_routes.py              # Routes NLP/FAISS
â”‚   â”‚   â”œâ”€â”€ reranking_routes.py        # Routes re-ranking
â”‚   â”‚   â””â”€â”€ user_query_routes.py       # Routes requÃªtes utilisateur
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ controllers/                # ContrÃ´leurs HTTP
â”‚   â”‚   â”œâ”€â”€ workflow_controller.py     # ContrÃ´leur workflow
â”‚   â”‚   â”œâ”€â”€ crawler_controller.py      # ContrÃ´leur crawler
â”‚   â”‚   â”œâ”€â”€ reranking_controller.py    # ContrÃ´leur re-ranking
â”‚   â”‚   â””â”€â”€ user_query_controller.py   # ContrÃ´leur requÃªtes
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ services/                   # Logique mÃ©tier
â”‚   â”‚   â”œâ”€â”€ workflow_service.py        # ğŸ¯ Orchestration workflow (6 Ã©tapes)
â”‚   â”‚   â”œâ”€â”€ crawler_service.py         # Crawling multi-sources
â”‚   â”‚   â”œâ”€â”€ nlp_service.py             # FAISS + Embeddings
â”‚   â”‚   â”œâ”€â”€ reranking_service.py       # Cross-Encoder + Fine-tuning
â”‚   â”‚   â””â”€â”€ user_query_service.py      # Gestion requÃªtes utilisateur
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ models/                     # ModÃ¨les Pydantic (validation)
â”‚       â”œâ”€â”€ workflow_model.py          # ModÃ¨les du workflow
â”‚       â”œâ”€â”€ crawler_model.py           # ModÃ¨les de crawling
â”‚       â”œâ”€â”€ reranking_model.py         # ModÃ¨les de re-ranking
â”‚       â””â”€â”€ user_query_model.py        # ModÃ¨les de requÃªtes
â”‚
â”œâ”€â”€ ğŸ“ data/                           # DonnÃ©es persistantes
â”‚   â”œâ”€â”€ faiss_index.index              # Index FAISS
â”‚   â””â”€â”€ faiss_index.ids                # IDs des ressources
â”‚
â”œâ”€â”€ ğŸ“ models/                         # ModÃ¨les ML
â”‚   â””â”€â”€ cross_encoder_finetuned/       # ModÃ¨le BERT fine-tunÃ©
â”‚       â”œâ”€â”€ pytorch_model.bin          # Poids du modÃ¨le
â”‚       â”œâ”€â”€ config.json                # Configuration
â”‚       â””â”€â”€ training_metadata.pkl      # MÃ©tadonnÃ©es d'entraÃ®nement
â”‚
â”œâ”€â”€ ğŸ“ docs/                           # Documentation
â”‚   â”œâ”€â”€ WORKFLOW_GUIDE.md              # ğŸ“– Guide complet du workflow
â”‚   â”œâ”€â”€ NLP_SERVICE.md                 # Documentation NLP/FAISS
â”‚   â””â”€â”€ RERANKING_SERVICE.md           # Documentation Re-ranking
â”‚
â”œâ”€â”€ ğŸ“ notebooks/                      # Jupyter Notebooks
â”‚   â”œâ”€â”€ fine_tune_cross_encoder.ipynb  # Fine-tuning du modÃ¨le
â”‚   â””â”€â”€ FINE_TUNING_GUIDE.md           # Guide de fine-tuning
â”‚
â”œâ”€â”€ ğŸ“ public/                         # Fichiers statiques
â”‚   â””â”€â”€ index.html                     # Page d'accueil
â”‚
â””â”€â”€ ğŸ“ scripts/                        # Scripts utilitaires
    â”œâ”€â”€ test_workflow.py               # Tests du workflow
    â””â”€â”€ examples_workflow.sh           # Exemples curl
```

---

## ğŸš€ Installation

### PrÃ©requis

- **Python 3.10+**
- **MongoDB 6.0+** (ou Docker)
- **8 GB RAM minimum** (16 GB recommandÃ© pour le fine-tuning)
- **Connexion Internet** (pour le crawling)

### Installation Rapide

#### Option 1 : Avec Docker (RecommandÃ©)

```bash
# 1. Cloner le repository
git clone <votre-repo-url>
cd crawler-enduranker-api

# 2. DÃ©marrer MongoDB avec Docker
docker-compose up -d

# 3. CrÃ©er l'environnement virtuel
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# ou venv\Scripts\activate  # Windows

# 4. Installer les dÃ©pendances
pip install -r requirements.txt

# 5. Configurer les variables d'environnement
cp .env.example .env
# Ã‰diter .env si nÃ©cessaire

# 6. DÃ©marrer l'API
python main.py
```

#### Option 2 : MongoDB Local

```bash
# 1-3. MÃªme chose que l'option 1

# 4. VÃ©rifier que MongoDB est en cours d'exÃ©cution
sudo systemctl status mongod
sudo systemctl start mongod  # Si nÃ©cessaire

# 5-6. Installer dÃ©pendances et dÃ©marrer
pip install -r requirements.txt
python main.py
```

### Configuration

#### Variables d'Environnement (.env)

```bash
# Application
APP_NAME=EduRanker Crawler API
APP_VERSION=1.0.0
DEBUG=True
HOST=0.0.0.0
PORT=8000

# MongoDB
MONGODB_URL=mongodb://localhost:27017
MONGODB_DB_NAME=eduranker_db

# FAISS
FAISS_INDEX_PATH=data/faiss_index

# Logging
LOG_LEVEL=INFO
```

### VÃ©rification de l'Installation

```bash
# 1. VÃ©rifier que l'API fonctionne
curl http://localhost:8000/health

# 2. AccÃ©der Ã  la documentation
# Ouvrir http://localhost:8000/docs dans votre navigateur

# 3. Tester le workflow
curl -X POST "http://localhost:8000/api/workflow/process" \
  -H "Content-Type: application/json" \
  -d '{"question": "Comment apprendre Python ?"}'
```

---

## ğŸ’» Utilisation

### DÃ©marrage Rapide

```bash
# Terminal 1 : DÃ©marrer MongoDB (si Docker)
docker-compose up -d

# Terminal 2 : DÃ©marrer l'API
python main.py

# Terminal 3 : Tester le workflow
curl -X POST "http://localhost:8000/api/workflow/process" \
  -H "Content-Type: application/json" \
  -d '{"question": "Comment apprendre Python ?"}'
```

### Exemples d'Utilisation

#### 1. Workflow Global (RecommandÃ©)

```python
import requests

# Obtenir le top 10 pour une question
response = requests.post(
    "http://localhost:8000/api/workflow/process",
    json={
        "question": "Comment dÃ©buter en data science ?",
        "sources": ["wikipedia", "github"],
        "top_k_final": 10
    }
)

results = response.json()
print(f"âœ… {results['total_resultats_final']} ressources trouvÃ©es")

for i, resource in enumerate(results['resultats'], 1):
    print(f"\n{i}. {resource['titre']}")
    print(f"   Score: {resource['score_final']:.3f}")
    print(f"   URL: {resource['url']}")
    print(f"   Source: {resource['source']}")
```

#### 2. Crawling Seul

```bash
curl -X POST "http://localhost:8000/api/crawler/collect" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "TensorFlow tutorial",
    "max_par_site": 15,
    "sources": ["github", "medium"],
    "langues": ["en"]
  }'
```

#### 3. Recherche SÃ©mantique

```bash
curl -X POST "http://localhost:8000/api/nlp/search" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "natural language processing",
    "top_k": 20
  }'
```

#### 4. Feedback sur une Recommandation

```bash
curl -X POST "http://localhost:8000/api/reranking/feedback" \
  -H "Content-Type: application/json" \
  -d '{
    "inference_id": "507f1f77bcf86cd799439011",
    "feedback_type": "positive"
  }'
```

---

## ğŸ“š API Endpoints

### Workflow Global

| Endpoint | MÃ©thode | Description |
|----------|---------|-------------|
| `/api/workflow/process` | POST | ğŸ”¥ **Workflow complet** : crawling â†’ recherche â†’ re-ranking |
| `/api/workflow/health` | GET | Health check du workflow |

### Crawler

| Endpoint | MÃ©thode | Description |
|----------|---------|-------------|
| `/api/crawler/collect` | POST | Collecter des ressources depuis les sources |
| `/api/crawler/search` | POST | Rechercher dans les ressources collectÃ©es |
| `/api/crawler/stats` | GET | Statistiques du crawler |

### NLP & FAISS

| Endpoint | MÃ©thode | Description |
|----------|---------|-------------|
| `/api/nlp/search` | POST | Recherche sÃ©mantique avec FAISS |
| `/api/nlp/index/rebuild` | POST | Reconstruire l'index FAISS |
| `/api/nlp/stats` | GET | Statistiques de l'index |
| `/api/nlp/index/add` | POST | Ajouter des ressources Ã  l'index |

### Re-ranking

| Endpoint | MÃ©thode | Description |
|----------|---------|-------------|
| `/api/reranking/search-with-reranking` | POST | Recherche + re-ranking automatique |
| `/api/reranking/rerank` | POST | Re-ranker des rÃ©sultats existants |
| `/api/reranking/feedback` | POST | Soumettre un feedback utilisateur |
| `/api/reranking/fine-tune` | POST | Lancer le fine-tuning du modÃ¨le |
| `/api/reranking/inferences/{query_id}` | GET | RÃ©cupÃ©rer les infÃ©rences |

### RequÃªtes Utilisateur

| Endpoint | MÃ©thode | Description |
|----------|---------|-------------|
| `/api/queries/save` | POST | Sauvegarder une question utilisateur |
| `/api/queries/recent` | GET | RÃ©cupÃ©rer les requÃªtes rÃ©centes |
| `/api/queries/stats` | GET | Statistiques des requÃªtes |

### Documentation

| URL | Description |
|-----|-------------|
| `http://localhost:8000` | Page d'accueil |
| `http://localhost:8000/docs` | ğŸ“– Documentation Swagger UI (interactive) |
| `http://localhost:8000/redoc` | Documentation ReDoc |
| `http://localhost:8000/health` | Health check API |

---

## ğŸ› ï¸ Technologies

### Backend & API

- **[FastAPI](https://fastapi.tiangolo.com/)** - Framework web moderne et performant
- **[Pydantic](https://docs.pydantic.dev/)** - Validation des donnÃ©es
- **[Uvicorn](https://www.uvicorn.org/)** - Serveur ASGI

### Base de DonnÃ©es

- **[MongoDB](https://www.mongodb.com/)** - Base NoSQL pour stockage flexible
- **[Motor](https://motor.readthedocs.io/)** - Driver MongoDB asynchrone
- **[PyMongo](https://pymongo.readthedocs.io/)** - Driver MongoDB

### Machine Learning & NLP

- **[Sentence-Transformers](https://www.sbert.net/)** - Embeddings sÃ©mantiques
  - ModÃ¨le: `all-MiniLM-L6-v2` (384 dimensions)
- **[FAISS](https://github.com/facebookresearch/faiss)** - Recherche vectorielle ultra-rapide
- **[Transformers](https://huggingface.co/transformers/)** (HuggingFace) - Cross-Encoder
  - ModÃ¨le: `ms-marco-MiniLM-L-6-v2`
- **[PyTorch](https://pytorch.org/)** - Framework deep learning

### Crawling & Web Scraping

- **[Requests](https://requests.readthedocs.io/)** - RequÃªtes HTTP
- **[BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/)** - Parsing HTML
- **Wikipedia API** - AccÃ¨s aux articles Wikipedia
- **GitHub API** - AccÃ¨s aux repositories

### Utilitaires

- **[Python-dotenv](https://github.com/theskumar/python-dotenv)** - Variables d'environnement
- **NumPy** - Calculs numÃ©riques
- **Pandas** - Analyse de donnÃ©es

---

## ğŸ“– Documentation

### Guides Complets

| Document | Description | Temps de Lecture |
|----------|-------------|------------------|
| **[WORKFLOW_GUIDE.md](docs/WORKFLOW_GUIDE.md)** | ğŸ“– Guide complet du workflow global | 30 min |
| **[NLP_SERVICE.md](docs/NLP_SERVICE.md)** | Documentation NLP et FAISS | 20 min |
| **[RERANKING_SERVICE.md](docs/RERANKING_SERVICE.md)** | Documentation Re-ranking | 20 min |
| **[FINE_TUNING_GUIDE.md](notebooks/FINE_TUNING_GUIDE.md)** | Guide de fine-tuning du modÃ¨le | 45 min |

### Quick Start

| Document | Description | Temps |
|----------|-------------|-------|
| **[QUICKSTART_WORKFLOW.md](QUICKSTART_WORKFLOW.md)** | DÃ©marrage rapide workflow | 5 min |
| **[INSTALLATION_COMPLETE.md](INSTALLATION_COMPLETE.md)** | Installation complÃ¨te | 10 min |
| **[SUMMARY.md](SUMMARY.md)** | RÃ©sumÃ© du projet | 10 min |

### Fichiers Techniques

- `BUGFIX_INFERENCE.md` - Corrections de bugs
- `WORKFLOW_IMPLEMENTATION.md` - DÃ©tails d'implÃ©mentation
- `COMMANDES_ESSENTIELLES.sh` - Commandes utiles

---

## ğŸ§ª Tests

### Tests AutomatisÃ©s

```bash
# Test complet du workflow
python test_workflow.py

# Exemples variÃ©s (5 cas d'usage)
./examples_workflow.sh

# Commandes essentielles
./COMMANDES_ESSENTIELLES.sh
```

### Tests Manuels

```bash
# 1. Health Check
curl http://localhost:8000/health
curl http://localhost:8000/api/workflow/health

# 2. Test workflow simple
curl -X POST "http://localhost:8000/api/workflow/process" \
  -H "Content-Type: application/json" \
  -d '{"question": "Python tutorial"}'

# 3. Test avec paramÃ¨tres
curl -X POST "http://localhost:8000/api/workflow/process" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Deep learning for beginners",
    "max_par_site": 10,
    "sources": ["wikipedia"],
    "langues": ["en"],
    "top_k_final": 5
  }'
```

### VÃ©rification MongoDB

```bash
# Se connecter Ã  MongoDB
docker exec -it mongodb mongo eduranker_db
# ou
mongosh eduranker_db

# Commandes MongoDB
show collections
db.ressources_educatives.count()
db.users_queries.find().sort({date_creation:-1}).limit(5).pretty()
db.inference.find().sort({date_inference:-1}).limit(5).pretty()
```

---

## âš¡ Performances

### Temps d'ExÃ©cution

| Ã‰tape | DurÃ©e Typique | Notes |
|-------|---------------|-------|
| Sauvegarde question | < 0.1s | Quasi instantanÃ© |
| Crawling | 10-30s | DÃ©pend des sources et du rÃ©seau |
| Index FAISS | 1-5s | DÃ©pend du nombre de ressources |
| Recherche FAISS | 0.1-0.5s | Ultra-rapide (mÃªme 100k+ vecteurs) |
| Re-ranking | 1-3s | DÃ©pend du top_k |
| Sauvegarde infÃ©rences | < 0.5s | Asynchrone |
| **TOTAL** | **12-40s** | Acceptable pour un workflow complet |

### Optimisations

#### Pour la Vitesse
```json
{
  "max_par_site": 10,
  "sources": ["wikipedia"],
  "top_k_faiss": 30,
  "top_k_final": 5
}
```

#### Pour la PrÃ©cision
```json
{
  "max_par_site": 25,
  "sources": ["wikipedia", "github", "medium"],
  "top_k_faiss": 100,
  "top_k_final": 15
}
```

### CapacitÃ©

- **MongoDB** : IllimitÃ© (disque)
- **FAISS Index** : Jusqu'Ã  1M+ de vecteurs (16GB RAM)
- **Concurrent requests** : 100+ (avec Uvicorn workers)

---

## ğŸ’¾ Base de DonnÃ©es MongoDB

### Collections

#### 1. `ressources_educatives`
Stocke toutes les ressources crawlÃ©es avec leurs embeddings.

```javascript
{
  "_id": ObjectId("..."),
  "titre": "Introduction au Machine Learning",
  "url": "https://...",
  "source": "wikipedia",
  "langue": "fr",
  "auteur": "Wikipedia Contributors",
  "date": "2024-01-15",
  "texte": "Le machine learning est...",
  "embedding": [0.1, -0.2, ...],  // 384 dimensions
  "popularite": 150,
  "type_ressource": "article",
  "mots_cles": ["ML", "IA"],
  "requete_originale": "machine learning",
  "date_collecte": ISODate("2024-01-20")
}
```

#### 2. `users_queries`
Stocke les questions des utilisateurs.

```javascript
{
  "_id": ObjectId("..."),
  "question": "Comment apprendre Python ?",
  "embedding": [0.15, -0.23, ...],  // 384 dimensions
  "langue_detectee": "fr",
  "date_creation": ISODate("2024-01-20")
}
```

#### 3. `inference`
Trackingdes recommandations et feedbacks.

```javascript
{
  "_id": ObjectId("..."),
  "user_query_id": "507f...",
  "resource_id": "507f...",
  "faiss_score": 0.85,
  "reranking_score": 0.92,
  "final_score": 0.89,
  "rank": 1,
  "feedback": "positive",  // ou null
  "date_inference": ISODate("2024-01-20"),
  "date_feedback": ISODate("2024-01-20"),
  "session_id": "user_123"
}
```

### Index MongoDB

Des index sont crÃ©Ã©s automatiquement pour optimiser les performances :

- `ressources_educatives` : `source`, `langue`, `requete_originale`
- `users_queries` : `date_creation`
- `inference` : `user_query_id`, `resource_id`, `feedback`, `session_id`, `date_inference`

---

## ğŸ¯ SystÃ¨me d'InfÃ©rence et Feedback

### Fonctionnement

1. **Tracking Automatique** : Chaque recommandation est sauvegardÃ©e dans `inference`
2. **Feedback Utilisateur** : Les utilisateurs peuvent donner leur avis (positive/negative/click/view)
3. **Analyse** : Les donnÃ©es sont analysÃ©es pour comprendre les performances
4. **Fine-tuning** : Le modÃ¨le est amÃ©liorÃ© avec les feedbacks positifs/nÃ©gatifs

### Workflow Feedback

```
Recherche â†’ RÃ©sultats avec inference_id â†’ Utilisateur interagit â†’ Feedback
                                                                      â†“
                                             MongoDB (inference collection)
                                                                      â†“
                                                Fine-tuning PÃ©riodique
                                                                      â†“
                                                  ModÃ¨le AmÃ©liorÃ©
```

### Exemple IntÃ©gration Frontend

```javascript
// 1. Workflow complet
const response = await fetch('/api/workflow/process', {
  method: 'POST',
  headers: {'Content-Type': 'application/json'},
  body: JSON.stringify({
    question: userInput,
    top_k_final: 10
  })
});

const data = await response.json();

// 2. Afficher rÃ©sultats avec handlers de feedback
data.resultats.forEach(resource => {
  const card = createResourceCard(resource);
  
  // Bouton Like
  card.querySelector('.like-btn').onclick = async () => {
    await fetch('/api/reranking/feedback', {
      method: 'POST',
      headers: {'Content-Type': 'application/json'},
      body: JSON.stringify({
        inference_id: resource.id_inference,
        feedback_type: 'positive'
      })
    });
    showToast('Merci pour votre feedback !');
  };
  
  // Tracking des clics
  card.querySelector('.resource-link').onclick = async () => {
    await fetch('/api/reranking/feedback', {
      method: 'POST',
      headers: {'Content-Type': 'application/json'},
      body: JSON.stringify({
        inference_id: resource.id_inference,
        feedback_type: 'click'
      })
    });
  };
});
```

---

## ğŸ”§ Fine-Tuning du ModÃ¨le

### Processus

1. **Collecter des feedbacks** (minimum 50-100)
2. **Lancer le fine-tuning** via API ou notebook
3. **Ã‰valuer le nouveau modÃ¨le**
4. **DÃ©ployer en production**

### Via API

```bash
curl -X POST "http://localhost:8000/api/reranking/fine-tune?num_epochs=3" \
  -H "Content-Type: application/json"
```

### Via Notebook

```bash
jupyter notebook notebooks/fine_tune_cross_encoder.ipynb
```

Le notebook guide Ã  travers :
- Chargement des donnÃ©es de feedback
- PrÃ©paration des paires (query, resource, label)
- Configuration du fine-tuning
- EntraÃ®nement du modÃ¨le
- Ã‰valuation des performances
- Sauvegarde du modÃ¨le

### MÃ©triques

Le systÃ¨me gÃ©nÃ¨re automatiquement :
- **Accuracy** : PrÃ©cision globale
- **Precision/Recall** : Par classe (positive/negative)
- **F1-Score** : Mesure harmonique
- **Confusion Matrix** : Visualisation des erreurs
- **Courbe ROC** : Performance du classifieur

---

## ğŸš§ DÃ©ploiement

### Production

#### Option 1 : Docker (RecommandÃ©)

```dockerfile
# Dockerfile
FROM python:3.10-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD ["python", "main.py"]
```

```bash
# Build et run
docker build -t eduranker-api .
docker run -p 8000:8000 --env-file .env eduranker-api
```

#### Option 2 : Serveur Linux

```bash
# Installer les dÃ©pendances systÃ¨me
sudo apt-get update
sudo apt-get install python3.10 python3-pip mongodb

# DÃ©ployer l'application
git clone <repo>
cd crawler-enduranker-api
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Utiliser systemd pour le dÃ©marrage automatique
sudo systemctl enable eduranker-api
sudo systemctl start eduranker-api
```

### Configuration Production

```env
# .env.production
DEBUG=False
LOG_LEVEL=WARNING
HOST=0.0.0.0
PORT=8000

# Utiliser MongoDB Atlas ou serveur dÃ©diÃ©
MONGODB_URL=mongodb://username:password@host:27017

# CORS spÃ©cifique
ALLOWED_ORIGINS=https://votre-frontend.com
```

---

## ğŸ¤ Contributing

### Comment Contribuer

1. **Fork** le projet
2. **CrÃ©er une branche** : `git checkout -b feature/AmazingFeature`
3. **Commit** : `git commit -m 'Add AmazingFeature'`
4. **Push** : `git push origin feature/AmazingFeature`
5. **Pull Request**

### Standards de Code

- **PEP 8** : Style guide Python
- **Type hints** : Utiliser les annotations de types
- **Docstrings** : Documenter les fonctions
- **Tests** : Ajouter des tests pour les nouvelles features

---

## ğŸ“ Roadmap

### Version 1.0 (Actuelle) âœ…
- [x] Workflow global complet
- [x] Crawler multi-sources
- [x] Recherche FAISS
- [x] Re-ranking cross-encoder
- [x] SystÃ¨me d'infÃ©rence
- [x] Fine-tuning

### Version 1.1 (En Cours) ğŸš§
- [ ] Cache Redis pour performances
- [ ] Pagination des rÃ©sultats
- [ ] Filtres avancÃ©s (date, source, langue)
- [ ] API rate limiting
- [ ] Webhooks pour notifications

### Version 2.0 (Futur) ğŸ”®
- [ ] Support de nouvelles sources (Stack Overflow, arXiv, Coursera)
- [ ] Recommandations personnalisÃ©es par utilisateur
- [ ] Multi-modal (images, vidÃ©os)
- [ ] GraphQL API
- [ ] Dashboard d'administration

---

## â“ FAQ

### Q: Combien de temps prend le workflow ?
**R:** Entre 12 et 40 secondes selon les paramÃ¨tres et la connexion internet.

### Q: Combien de ressources puis-je stocker ?
**R:** IllimitÃ© dans MongoDB. L'index FAISS peut gÃ©rer 1M+ de vecteurs avec 16GB RAM.

### Q: Le modÃ¨le s'amÃ©liore-t-il automatiquement ?
**R:** Non, le fine-tuning doit Ãªtre lancÃ© manuellement aprÃ¨s collecte de feedbacks.

### Q: Puis-je ajouter mes propres sources ?
**R:** Oui, en crÃ©ant un nouveau spider dans `src/services/crawler_service.py`.

### Q: Les embeddings sont-ils gÃ©nÃ©rÃ©s automatiquement ?
**R:** Oui, automatiquement lors du crawling avec sentence-transformers.

### Q: Puis-je utiliser un autre modÃ¨le de re-ranking ?
**R:** Oui, modifier `RERANKING_MODEL` dans le service de re-ranking.

### Q: Comment sauvegarder l'index FAISS ?
**R:** L'index est sauvegardÃ© automatiquement dans `data/faiss_index`.

### Q: L'API est-elle prÃªte pour la production ?
**R:** Oui, avec quelques ajustements (CORS, rate limiting, monitoring).

---

## ğŸ“„ Licence

Ce projet est sous licence **MIT**. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

---

## ğŸ‘¥ Auteurs

- **Ã‰quipe EduRanker** - Projet Master 2 Data Science
- **Cours** : INF5101 Traitement multimÃ©dia des donnÃ©es
- **AnnÃ©e** : 2024-2025

---

## ğŸ™ Remerciements

- **FastAPI** pour le framework web excellent
- **HuggingFace** pour les modÃ¨les prÃ©-entraÃ®nÃ©s
- **Facebook AI** pour FAISS
- **MongoDB** pour la base de donnÃ©es
- **CommunautÃ© Open Source** pour tous les outils utilisÃ©s

---

## ğŸ“ Support

### Documentation
- ğŸ“– **Guides complets** : Dossier `/docs`
- ğŸŒ **API Docs** : http://localhost:8000/docs
- ğŸ“š **Notebooks** : Dossier `/notebooks`

### Contact
- ğŸ“§ **Email** : eduranker@example.com
- ğŸ’¬ **Issues** : [GitHub Issues](https://github.com/votre-repo/issues)
- ğŸ“ **Wiki** : [GitHub Wiki](https://github.com/votre-repo/wiki)

### Liens Utiles
- ğŸ”— **Repository** : https://github.com/votre-repo
- ğŸ“Š **Documentation complÃ¨te** : https://docs.eduranker.com
- ğŸ“ **Tutoriels** : https://tutorials.eduranker.com

---

<div align="center">

**â­ Si ce projet vous aide, n'hÃ©sitez pas Ã  mettre une Ã©toile ! â­**

Made with â¤ï¸ by EduRanker Team

</div>
