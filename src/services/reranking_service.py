"""
Service de Re-ranking avec Cross-Encoder pour affiner le classement des r√©sultats FAISS.
Ce service utilise un mod√®le BERT cross-encoder qui peut √™tre fine-tun√© sur les feedbacks utilisateurs.
"""

import logging
import pickle
import os
import time
from pathlib import Path
from typing import List, Dict, Tuple, Optional
import numpy as np
import pymongo
from datetime import datetime
from sentence_transformers import CrossEncoder
import torch

from src.models.reranking_model import (
    UserFeedbackModel,
    TrainingPairModel,
    FineTuningStatsModel,
    InferenceModel
)

logger = logging.getLogger(__name__)


class RerankingService:
    """Service pour le re-ranking avec cross-encoder et fine-tuning"""
    
    def __init__(
        self, 
        mongodb_url: str, 
        mongodb_db: str, 
        model_name: str = "cross-encoder/ms-marco-MiniLM-L-6-v2",
        model_path: str = "models/cross_encoder_finetuned"
    ):
        """
        Initialise le service de re-ranking
        
        Args:
            mongodb_url: URL de connexion MongoDB
            mongodb_db: Nom de la base de donn√©es
            model_name: Nom du mod√®le cross-encoder de base
            model_path: Chemin pour sauvegarder le mod√®le fine-tun√©
        """
        self.mongodb_url = mongodb_url
        self.mongodb_db = mongodb_db
        self.feedback_collection = "user_feedbacks"
        self.inference_collection = "inference"
        self.model_path = "models/cross_encoder_finetuned"
        self.base_model_name = model_name
        
        # Cr√©er le dossier pour le mod√®le s'il n'existe pas
        Path(model_path).mkdir(parents=True, exist_ok=True)
        
        # Charger le cross-encoder
        self._charger_modele()
        
    def _charger_modele(self):
        """Charge le mod√®le cross-encoder (fine-tun√© ou de base)"""
        try:
            # V√©rifier si un mod√®le fine-tun√© existe
            config_file = os.path.join(self.model_path, "config.json")
            
            if os.path.exists(config_file):
                # Charger le mod√®le fine-tun√©
                logger.info(f"üì• Chargement du mod√®le fine-tun√© depuis {self.model_path}...")
                self.cross_encoder = CrossEncoder(self.model_path)
                logger.info("‚úÖ Mod√®le fine-tun√© charg√© avec succ√®s")
            else:
                # Charger le mod√®le de base depuis HuggingFace
                logger.info(f"üì• Aucun mod√®le fine-tun√© trouv√© dans {self.model_path}")
                logger.info(f"üì• Chargement du mod√®le de base {self.base_model_name}...")
                self.cross_encoder = CrossEncoder(self.base_model_name)
                logger.info("‚úÖ Mod√®le de base charg√© avec succ√®s")
                logger.info("üí° Pour utiliser un mod√®le fine-tun√©, ex√©cutez le notebook: notebooks/fine_tune_cross_encoder.ipynb")
                
        except Exception as e:
            logger.error(f"‚ùå Erreur chargement mod√®le: {e}")
            logger.warning("‚ö†Ô∏è  Le mod√®le cross-encoder n'a pas pu √™tre charg√©.")
            logger.warning("‚ö†Ô∏è  Le service fonctionnera en mode d√©grad√© (sans re-ranking).")
            logger.warning("‚ö†Ô∏è  Solutions possibles :")
            logger.warning("    1. Augmenter le timeout : export HF_HUB_DOWNLOAD_TIMEOUT=600")
            logger.warning(f"    2. T√©l√©charger le mod√®le manuellement : huggingface-cli download {self.base_model_name}")
            logger.warning("    3. Utiliser un miroir : export HF_ENDPOINT=https://hf-mirror.com")
            logger.warning("    4. Consulter TROUBLESHOOTING.md pour plus de solutions")
            self.cross_encoder = None  # Mode d√©grad√©
    
    async def reranker_resultats(
        self,
        question: str,
        resultats_faiss: List[Dict],
        top_k: int = 10
    ) -> List[Dict]:
        """
        Re-classe les r√©sultats FAISS en utilisant le cross-encoder
        
        Args:
            question: Question de l'utilisateur
            resultats_faiss: R√©sultats de la recherche FAISS
            top_k: Nombre de r√©sultats finaux √† retourner
            
        Returns:
            Liste de r√©sultats re-class√©s avec scores
        """
        if not resultats_faiss:
            return []
        
        # Mode d√©grad√© : si le mod√®le n'est pas charg√©, retourner les r√©sultats FAISS sans re-ranking
        if self.cross_encoder is None:
            logger.warning("‚ö†Ô∏è  Cross-encoder non disponible, retour des r√©sultats FAISS sans re-ranking")
            resultats_tries = resultats_faiss[:top_k]
            for i, res in enumerate(resultats_tries, 1):
                res['rank'] = i
                # R√©cup√©rer le score FAISS (peut √™tre 'score_faiss' ou 'score_similarite')
                res['faiss_score'] = res.get('score_faiss', res.get('score_similarite', 0.0))
                res['reranking_score'] = None
                res['final_score'] = res['faiss_score']
            return resultats_tries
        
        try:
            logger.info(f"üîÑ Re-ranking de {len(resultats_faiss)} r√©sultats avec cross-encoder...")

            self._charger_modele()
            
            # Pr√©parer les paires (question, document)
            paires = []
            for res in resultats_faiss:
                # Cr√©er un texte repr√©sentatif du document
                doc_text = self._creer_texte_document(res)
                paires.append([question, doc_text])
            
            # Pr√©dire les scores avec le cross-encoder
            scores = self.cross_encoder.predict(paires, show_progress_bar=False)
            
            # Ajouter les scores aux r√©sultats
            for i, res in enumerate(resultats_faiss):
                res['reranking_score'] = float(scores[i])
                # R√©cup√©rer le score FAISS (peut √™tre 'score_faiss' ou 'score_similarite')
                res['faiss_score'] = res.get('score_faiss', res.get('score_similarite', 0.0))
                # Score final combin√© (moyenne pond√©r√©e)
                res['final_score'] = self._calculer_score_final(
                    res['faiss_score'], 
                    res['reranking_score']
                )
            
            # Trier par score final d√©croissant
            resultats_tries = sorted(
                resultats_faiss, 
                key=lambda x: x['final_score'], 
                reverse=True
            )
            
            # Retourner les top_k meilleurs
            resultats_finaux = resultats_tries[:top_k]
            
            # Ajouter le rang
            for i, res in enumerate(resultats_finaux, 1):
                res['rank'] = i
            
            logger.info(f"‚úÖ Re-ranking termin√©: {len(resultats_finaux)} r√©sultats retourn√©s")
            return resultats_finaux
            
        except Exception as e:
            logger.error(f"‚ùå Erreur re-ranking: {e}")
            # En cas d'erreur, retourner les r√©sultats FAISS originaux
            return resultats_faiss[:top_k]
    
    def _creer_texte_document(self, ressource: Dict) -> str:
        """
        Cr√©e un texte repr√©sentatif du document pour le cross-encoder
        
        Args:
            ressource: Dictionnaire de la ressource
            
        Returns:
            Texte concat√©n√© (titre + extrait de texte)
        """
        titre = ressource.get('titre', '')
        texte = ressource.get('texte', '')
        
        # Limiter la longueur du texte pour le cross-encoder (max 512 tokens)
        # Approximation: 1 token ‚âà 4 caract√®res
        max_chars = 1500
        
        if texte and len(texte) > max_chars:
            texte = texte[:max_chars] + "..."
        
        # Combiner titre et texte
        doc_text = f"{titre}. {texte}" if titre and texte else titre or texte
        
        return doc_text
    
    def _calculer_score_final(
        self, 
        faiss_score: float, 
        reranking_score: float,
        alpha: float = 0.3
    ) -> float:
        """
        Calcule le score final combin√©
        
        Args:
            faiss_score: Score de similarit√© FAISS (0-1)
            reranking_score: Score du cross-encoder (-inf, +inf, typiquement -5 √† 5)
            alpha: Poids pour FAISS (1-alpha pour reranking)
            
        Returns:
            Score final combin√©
        """
        # Normaliser le score de reranking avec sigmo√Øde
        reranking_norm = 1 / (1 + np.exp(-reranking_score))
        
        # Combiner les scores
        final_score = alpha * faiss_score + (1 - alpha) * reranking_norm
        
        return float(final_score)
    
    async def sauvegarder_inference(
        self,
        user_query_id: str,
        resource_id: str,
        faiss_score: float,
        reranking_score: Optional[float],
        final_score: float,
        rank: int,
        session_id: Optional[str] = None
    ) -> Dict:
        """
        Sauvegarde une inf√©rence (recommandation) dans MongoDB
        
        Args:
            user_query_id: ID de la requ√™te utilisateur
            resource_id: ID de la ressource recommand√©e
            faiss_score: Score FAISS
            reranking_score: Score du cross-encoder (peut √™tre None)
            final_score: Score final combin√©
            rank: Position dans le classement
            session_id: ID de session optionnel
            
        Returns:
            Dictionnaire avec le statut
        """
        try:
            client = pymongo.MongoClient(self.mongodb_url)
            db = client[self.mongodb_db]
            inference_col = db[self.inference_collection]
            
            # Cr√©er l'inf√©rence
            inference = {
                "user_query_id": user_query_id,
                "resource_id": resource_id,
                "faiss_score": faiss_score,
                "reranking_score": reranking_score,
                "final_score": final_score,
                "rank": rank,
                "feedback": None,  # Initialement √† null
                "date_inference": datetime.now(),
                "session_id": session_id,
                "metadata": {}
            }
            
            # Sauvegarder dans MongoDB
            result = inference_col.insert_one(inference)
            
            client.close()
            
            logger.debug(f"üíæ Inf√©rence sauvegard√©e: rank {rank} pour requ√™te {user_query_id}")
            
            return {
                "status": "success",
                "inference_id": str(result.inserted_id)
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erreur sauvegarde inf√©rence: {e}")
            return {
                "status": "error",
                "message": str(e)
            }
    
    async def sauvegarder_feedback(
        self,
        inference_id: str,
        feedback_type: str
    ) -> Dict:
        """
        Met √† jour le feedback d'une inf√©rence
        
        Args:
            inference_id: ID de l'inf√©rence
            feedback_type: Type de feedback (like, dislike, click, view)
            
        Returns:
            Dictionnaire avec le statut
        """
        try:
            from bson import ObjectId
            
            # Se connecter √† MongoDB
            client = pymongo.MongoClient(self.mongodb_url)
            db = client[self.mongodb_db]
            inference_col = db[self.inference_collection]
            
            # V√©rifier que l'inf√©rence existe
            inference = inference_col.find_one({"_id": ObjectId(inference_id)})
            
            if not inference:
                client.close()
                return {
                    "status": "error",
                    "message": f"Inf√©rence {inference_id} introuvable"
                }
            
            # Mettre √† jour le feedback dans l'inf√©rence
            result = inference_col.update_one(
                {"_id": ObjectId(inference_id)},
                {
                    "$set": {
                        "feedback": feedback_type,
                        "date_feedback": datetime.now()
                    }
                }
            )
            
            # Sauvegarder aussi dans la collection user_feedbacks pour historique
            # feedback_col = db[self.feedback_collection]
            # feedback_doc = {
            #     "inference_id": inference_id,
            #     "user_query_id": inference.get("user_query_id"),
            #     "resource_id": inference.get("resource_id"),
            #     "feedback_type": feedback_type,
            #     "relevance_score": 1.0 if feedback_type == "like" else 0.0 if feedback_type == "dislike" else 0.5,
            #     "session_id": inference.get("session_id"),
            #     "date_feedback": datetime.now(),
            #     "metadata": {}
            # }
            # feedback_result = feedback_col.insert_one(feedback_doc)
            
            client.close()
            
            if result.modified_count > 0:
                logger.info(f"üíæ Feedback '{feedback_type}' sauvegard√© pour inf√©rence {inference_id}")
                return {
                    "status": "success",
                    "inference_id": inference_id,
                    # "feedback_id": str(feedback_result.inserted_id),
                    "message": "Feedback enregistr√© avec succ√®s"
                }
            else:
                return {
                    "status": "error",
                    "message": "Aucune modification effectu√©e"
                }
            
        except Exception as e:
            logger.error(f"‚ùå Erreur sauvegarde feedback: {e}")
            return {
                "status": "error",
                "message": str(e)
            }
    
    async def recuperer_donnees_entrainement(self) -> List[TrainingPairModel]:
        """
        R√©cup√®re les paires d'entra√Ænement depuis les feedbacks
        
        Returns:
            Liste de paires (query, document, label)
        """
        try:
            client = pymongo.MongoClient(self.mongodb_url)
            db = client[self.mongodb_db]
            feedback_col = db[self.feedback_collection]
            
            # R√©cup√©rer tous les feedbacks avec like/dislike
            feedbacks = list(feedback_col.find({
                "feedback_type": {"$in": ["like", "dislike"]}
            }))
            
            client.close()
            
            # Cr√©er les paires d'entra√Ænement
            training_pairs = []
            for fb in feedbacks:
                pair = TrainingPairModel(
                    query_text=fb.get("query_text", ""),
                    document_text=fb.get("resource_title", "") + ". " + fb.get("resource_text", ""),
                    label=fb.get("relevance_score", 0.5)
                )
                training_pairs.append(pair)
            
            logger.info(f"üìä {len(training_pairs)} paires d'entra√Ænement r√©cup√©r√©es")
            return training_pairs
            
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration donn√©es: {e}")
            return []
    
    async def fine_tuner_modele(
        self,
        num_epochs: int = 3,
        batch_size: int = 16,
        learning_rate: float = 2e-5
    ) -> Dict:
        """
        ‚ö†Ô∏è  D√âPR√âCI√â : Utilisez le notebook Jupyter pour le fine-tuning
        
        Le fine-tuning se fait maintenant via le notebook :
        notebooks/fine_tune_cross_encoder.ipynb
        
        Ce notebook offre :
        - Visualisations d√©taill√©es
        - M√©triques compl√®tes
        - Analyse des performances
        - Rapport d'entra√Ænement
        
        Args:
            num_epochs: Nombre d'√©poques d'entra√Ænement
            batch_size: Taille des batchs
            learning_rate: Taux d'apprentissage
            
        Returns:
            Message de redirection vers le notebook
        """
        logger.warning("‚ö†Ô∏è  Fine-tuning via API d√©pr√©ci√©. Utilisez le notebook Jupyter.")
        
        return {
            "status": "deprecated",
            "message": "Le fine-tuning via API est d√©pr√©ci√©. Utilisez le notebook Jupyter pour plus de contr√¥le et de visualisations.",
            "notebook_path": "notebooks/fine_tune_cross_encoder.ipynb",
            "instructions": [
                "1. Installer Jupyter : pip install jupyter notebook",
                "2. Lancer : cd notebooks && jupyter notebook",
                "3. Ouvrir : fine_tune_cross_encoder.ipynb",
                "4. Ex√©cuter les cellules dans l'ordre",
                "5. Le mod√®le fine-tun√© sera automatiquement utilis√© par l'API"
            ],
            "documentation": "notebooks/README.md"
        }
    
    async def obtenir_statistiques_feedback(self) -> FineTuningStatsModel:
        """
        Retourne les statistiques des feedbacks pour le fine-tuning
        
        Returns:
            Statistiques des feedbacks
        """
        try:
            client = pymongo.MongoClient(self.mongodb_url)
            db = client[self.mongodb_db]
            feedback_col = db[self.feedback_collection]
            
            # Compter les feedbacks
            total = feedback_col.count_documents({})
            likes = feedback_col.count_documents({"feedback_type": "like"})
            dislikes = feedback_col.count_documents({"feedback_type": "dislike"})
            
            client.close()
            
            # Charger les m√©tadonn√©es du mod√®le
            metadata_path = os.path.join(self.model_path, "metadata.pkl")
            model_version = None
            last_training = None
            
            if os.path.exists(metadata_path):
                with open(metadata_path, 'rb') as f:
                    metadata = pickle.load(f)
                    model_version = metadata.get("model_version")
                    training_date_str = metadata.get("training_date")
                    if training_date_str:
                        last_training = datetime.fromisoformat(training_date_str)
            
            stats = FineTuningStatsModel(
                nb_feedbacks_total=total,
                nb_likes=likes,
                nb_dislikes=dislikes,
                nb_training_pairs=likes + dislikes,
                model_version=model_version,
                last_training_date=last_training
            )
            
            return stats
            
        except Exception as e:
            logger.error(f"‚ùå Erreur statistiques: {e}")
            return FineTuningStatsModel(
                nb_feedbacks_total=0,
                nb_likes=0,
                nb_dislikes=0,
                nb_training_pairs=0
            )
    
    def predict_score(self, query: str, document: str) -> float:
        """
        Pr√©dit le score de pertinence pour une paire (query, document)
        
        Args:
            query: Texte de la requ√™te
            document: Texte du document
            
        Returns:
            Score de pertinence
        """
        try:
            score = self.cross_encoder.predict([[query, document]])[0]
            return float(score)
        except Exception as e:
            logger.error(f"‚ùå Erreur pr√©diction: {e}")
            return 0.0
    
    async def recuperer_inferences(self, user_query_id: str) -> List[Dict]:
        """
        R√©cup√®re toutes les inf√©rences pour une requ√™te utilisateur donn√©e
        
        Args:
            user_query_id: ID de la requ√™te utilisateur
            
        Returns:
            Liste des inf√©rences avec leurs scores et feedbacks
        """
        try:
            client = pymongo.MongoClient(self.mongodb_url)
            db = client[self.mongodb_db]
            inference_col = db[self.inference_collection]
            
            # R√©cup√©rer toutes les inf√©rences pour cette requ√™te
            inferences = list(inference_col.find(
                {"user_query_id": user_query_id}
            ).sort("rank", 1))  # Trier par rang croissant
            
            client.close()
            
            # Convertir les ObjectId en string
            for inf in inferences:
                inf['_id'] = str(inf['_id'])
            
            logger.info(f"üìä {len(inferences)} inf√©rences r√©cup√©r√©es pour requ√™te {user_query_id}")
            return inferences
            
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration inf√©rences: {e}")
            return []


# Instance singleton
_reranking_service_instance = None

def get_reranking_service(
    mongodb_url: str, 
    mongodb_db: str,
    model_name: str = "cross-encoder/ms-marco-MiniLM-L-6-v2",
    model_path: str = "models/cross_encoder_finetuned"
) -> RerankingService:
    """
    Obtenir l'instance du service de re-ranking (singleton)
    
    Args:
        mongodb_url: URL de connexion MongoDB
        mongodb_db: Nom de la base de donn√©es
        model_name: Nom du mod√®le cross-encoder
        model_path: Chemin du mod√®le fine-tun√©
        
    Returns:
        Instance du service de re-ranking
    """
    global _reranking_service_instance
    if _reranking_service_instance is None:
        _reranking_service_instance = RerankingService(
            mongodb_url, 
            mongodb_db, 
            model_name, 
            model_path
        )
    return _reranking_service_instance
