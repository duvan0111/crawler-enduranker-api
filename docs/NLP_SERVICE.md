# Service NLP avec FAISS - Documentation

## Vue d'ensemble

Le service NLP impl√©mente un syst√®me de recherche s√©mantique bas√© sur FAISS (Facebook AI Similarity Search) pour indexer et rechercher efficacement des ressources √©ducatives en utilisant leurs embeddings vectoriels.

## Architecture

### Composants principaux

1. **NLPService** (`src/services/nlp_service.py`)
   - G√©n√©ration d'embeddings avec sentence-transformers
   - Indexation FAISS (384 dimensions)
   - Recherche s√©mantique
   - Gestion de la persistance de l'index

2. **Routes API** (`src/routes/nlp_routes.py`)
   - `/api/nlp/recherche-semantique` - Recherche s√©mantique
   - `/api/nlp/statistiques-index` - Statistiques de l'index
   - `/api/nlp/reconstruire-index` - Reconstruction manuelle
   - `/api/nlp/ajouter-ressources` - Ajout manuel de ressources
   - `/api/nlp/generer-embedding` - Test de g√©n√©ration d'embedding

3. **Int√©gration au cycle de vie** (`main.py`)
   - Chargement/reconstruction de l'index au d√©marrage
   - Mise √† jour automatique apr√®s chaque crawl

## Fonctionnement

### 1. D√©marrage de l'application

Au d√©marrage, le syst√®me :
1. Initialise le service NLP
2. Essaie de charger l'index FAISS sauvegard√©
3. Si aucun index n'existe, reconstruit depuis MongoDB
4. Affiche les statistiques de l'index

```python
# Dans main.py - lifespan
nlp_service = get_nlp_service(mongodb_url, mongodb_db, index_path)

if nlp_service.charger_index():
    # Index charg√© depuis le disque
else:
    # Reconstruction depuis MongoDB
    await nlp_service.reconstruire_index_depuis_bd()
```

### 2. Crawl de nouvelles ressources

Lorsque de nouvelles ressources sont collect√©es :
1. Les embeddings sont g√©n√©r√©s avec sentence-transformers
2. Les ressources sont sauvegard√©es dans MongoDB
3. L'index FAISS est automatiquement mis √† jour

```python
# Dans crawler_service.py - _sauvegarder_mongodb
if nouveaux_ids:
    nlp_service = get_nlp_service(...)
    await nlp_service.ajouter_ressources_a_index(nouveaux_ids)
```

### 3. Recherche s√©mantique

Pour rechercher des ressources :
1. La question utilisateur est vectoris√©e
2. FAISS trouve les k plus proches voisins
3. Les ressources compl√®tes sont r√©cup√©r√©es depuis MongoDB

```python
# Exemple d'utilisation
resultats = await nlp_service.recherche_et_recuperer_ressources(
    question="machine learning en √©ducation",
    top_k=10
)
```

## Mod√®le d'embeddings

- **Mod√®le** : sentence-transformers/all-MiniLM-L6-v2
- **Dimensions** : 384
- **Normalisation** : Embeddings normalis√©s pour similarit√© cosine
- **Index FAISS** : IndexFlatIP (Inner Product)

## API Endpoints

### Recherche s√©mantique

```bash
POST /api/nlp/recherche-semantique?question=machine learning&top_k=10
```

**R√©ponse** :
```json
{
  "status": "success",
  "question": "machine learning",
  "nb_resultats": 10,
  "resultats": [
    {
      "titre": "Introduction au Machine Learning",
      "url": "https://...",
      "source": "wikipedia",
      "texte": "...",
      "score_similarite": 0.85,
      ...
    }
  ]
}
```

### Statistiques de l'index

```bash
GET /api/nlp/statistiques-index
```

**R√©ponse** :
```json
{
  "status": "success",
  "statistiques": {
    "index_existe": true,
    "nb_vecteurs": 150,
    "dimension": 384,
    "type_index": "IndexFlatIP (Inner Product)",
    "nb_resource_ids": 150
  }
}
```

### Reconstruction manuelle

```bash
POST /api/nlp/reconstruire-index
```

Utile pour :
- R√©parer un index corrompu
- Recharger apr√®s une modification manuelle de la BD
- Maintenance

## Persistance

### Fichiers sauvegard√©s

- `data/faiss_index.index` : Index FAISS binaire
- `data/faiss_index.ids` : Liste des IDs MongoDB (pickle)

### Sauvegarde automatique

L'index est automatiquement sauvegard√© :
- Apr√®s reconstruction
- Apr√®s ajout de nouvelles ressources

## Performance

### Recherche
- **Complexit√©** : O(n) avec IndexFlatIP (recherche exhaustive)
- **Pr√©cision** : Maximale (pas d'approximation)
- **Vitesse** : ~1ms pour 1000 vecteurs

### Optimisations possibles

Pour de tr√®s grandes bases (>100k vecteurs) :
- Utiliser IndexIVFFlat (quantization)
- Utiliser IndexHNSW (graphes)
- GPU avec faiss-gpu

## Exemple d'utilisation compl√®te

### 1. D√©marrer l'application

```bash
uvicorn main:app --reload
```

L'index est charg√©/reconstruit automatiquement.

### 2. Crawler des ressources

```bash
POST /api/crawler/collecter
{
  "question": "deep learning",
  "max_par_site": 15
}
```

Les nouvelles ressources sont automatiquement index√©es.

### 3. Rechercher s√©mantiquement

```bash
POST /api/nlp/recherche-semantique?question=apprentissage profond&top_k=5
```

Retourne les 5 ressources les plus similaires, m√™me si la question est en fran√ßais et les ressources en anglais.

## Variables d'environnement

```bash
# Chemin de l'index FAISS
FAISS_INDEX_PATH=data/faiss_index

# MongoDB (d√©j√† existant)
MONGODB_URL=mongodb://localhost:27017
MONGODB_DB_NAME=eduranker_db
```

## Logging

Le service NLP utilise le logger Python standard :

```python
import logging
logger = logging.getLogger(__name__)
```

Messages cl√©s :
- üì• Chargement du mod√®le
- ‚úÖ Succ√®s des op√©rations
- üîÑ Reconstruction de l'index
- üîç R√©sultats de recherche
- ‚ùå Erreurs

## Tests

### Tester la g√©n√©ration d'embedding

```bash
POST /api/nlp/generer-embedding?texte=hello world
```

### Tester la recherche

```bash
POST /api/nlp/recherche-semantique?question=test&top_k=5
```

### V√©rifier les statistiques

```bash
GET /api/nlp/statistiques-index
```

## Maintenance

### Reconstruire l'index

Si l'index semble corrompu ou obsol√®te :

```bash
POST /api/nlp/reconstruire-index
```

### Sauvegarder l'index

L'index est sauvegard√© automatiquement, mais vous pouvez aussi :

```bash
# Copier les fichiers
cp data/faiss_index.index data/backups/
cp data/faiss_index.ids data/backups/
```

## D√©pannage

### L'index est vide au d√©marrage

1. V√©rifier que MongoDB contient des ressources avec embeddings
2. V√©rifier les logs au d√©marrage
3. Forcer la reconstruction avec `/api/nlp/reconstruire-index`

### R√©sultats de recherche non pertinents

1. V√©rifier la qualit√© des embeddings g√©n√©r√©s
2. V√©rifier que les textes des ressources sont significatifs
3. Augmenter `top_k` pour plus de r√©sultats

### Performance lente

1. V√©rifier le nombre de vecteurs dans l'index
2. Consid√©rer une mise √† niveau vers IndexIVF pour >100k vecteurs
3. Utiliser faiss-gpu pour de tr√®s grandes bases

## √âvolutions futures

1. **Clustering** : Regrouper les ressources similaires
2. **R√©indexation incr√©mentale** : Optimiser les mises √† jour
3. **Multi-index** : Un index par domaine/langue
4. **M√©tadonn√©es FAISS** : Filtrage par source/langue dans FAISS
5. **A/B Testing** : Comparer diff√©rents mod√®les d'embeddings
