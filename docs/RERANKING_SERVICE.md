# Service de Re-ranking avec Cross-Encoder - Documentation

## ğŸ¯ Vue d'ensemble

Le service de re-ranking utilise un **cross-encoder BERT** pour affiner le classement des rÃ©sultats obtenus via FAISS. Contrairement aux bi-encoders (utilisÃ©s dans FAISS), le cross-encoder traite simultanÃ©ment la requÃªte et le document, offrant une prÃ©cision supÃ©rieure au prix d'une vitesse rÃ©duite.

## ğŸ—ï¸ Architecture

### Pipeline de recherche complet

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RequÃªte user    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. RECHERCHE FAISS             â”‚
â”‚     (Bi-encoder)                â”‚
â”‚                                 â”‚
â”‚  â€¢ Rapide (< 1ms)               â”‚
â”‚  â€¢ Recall Ã©levÃ©                 â”‚
â”‚  â€¢ Top-K candidats (50-100)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. RE-RANKING                  â”‚
â”‚     (Cross-encoder)             â”‚
â”‚                                 â”‚
â”‚  â€¢ Plus lent (~10-50ms)         â”‚
â”‚  â€¢ PrÃ©cision Ã©levÃ©e             â”‚
â”‚  â€¢ Score de pertinence fin      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. RÃ‰SULTATS FINAUX            â”‚
â”‚                                 â”‚
â”‚  â€¢ Top-10 meilleurs rÃ©sultats   â”‚
â”‚  â€¢ Classement optimal           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### DiffÃ©rence Bi-encoder vs Cross-encoder

| Aspect | Bi-encoder (FAISS) | Cross-encoder (Re-ranking) |
|--------|-------------------|---------------------------|
| **Architecture** | Encode query et docs sÃ©parÃ©ment | Encode query+doc ensemble |
| **Vitesse** | TrÃ¨s rapide (< 1ms) | Plus lent (10-50ms) |
| **PrÃ©cision** | Bonne | Excellente |
| **Usage** | PremiÃ¨re Ã©tape (recall) | Seconde Ã©tape (precision) |
| **ScalabilitÃ©** | Millions de docs | Centaines de docs |

## ğŸ§  ModÃ¨le Cross-Encoder

### ModÃ¨le de base

**Nom**: `cross-encoder/ms-marco-MiniLM-L-6-v2`

- PrÃ©-entraÃ®nÃ© sur MS MARCO (Microsoft Machine Reading Comprehension)
- 22.7M de paramÃ¨tres
- OptimisÃ© pour la recherche de passage
- Support multilingue limitÃ© (principalement EN)

### Fonctionnement

```python
# Input: Paire (query, document)
input_text = "[CLS] query [SEP] document [SEP]"

# BERT processing
hidden_states = bert_model(input_text)

# Classification head
relevance_score = classifier(hidden_states[CLS])

# Output: Score de pertinence (-âˆ, +âˆ)
# Typiquement entre -5 et +5
```

## ğŸ’¾ DonnÃ©es d'entraÃ®nement

### Collecte des feedbacks

Les feedbacks utilisateurs sont sauvegardÃ©s dans MongoDB :

```javascript
{
  _id: ObjectId("..."),
  user_query_id: "507f1f77bcf86cd799439011",
  resource_id: "507f1f77bcf86cd799439012",
  query_text: "machine learning tutorial",
  resource_title: "Introduction to ML",
  resource_text: "Machine learning is...",
  feedback_type: "like",  // like, dislike, click, view
  relevance_score: 1.0,   // 1.0 = pertinent, 0.0 = non pertinent
  session_id: "session_123",
  date_feedback: ISODate("2024-01-20T10:30:00Z")
}
```

### Types de feedback

| Type | Label | Utilisation |
|------|-------|-------------|
| `like` | 1.0 | Ressource pertinente (feedback explicite) |
| `dislike` | 0.0 | Ressource non pertinente (feedback explicite) |
| `click` | 0.75 | Click sur la ressource (feedback implicite) |
| `view` | 0.5 | Vue de la ressource (feedback faible) |

## ğŸ“ Fine-tuning

### PrÃ©requis

- **Minimum**: 10 feedbacks (like/dislike)
- **RecommandÃ©**: 100+ feedbacks pour de bons rÃ©sultats
- **Optimal**: 1000+ feedbacks

### Processus de fine-tuning

```python
# 1. RÃ©cupÃ©ration des feedbacks depuis MongoDB
feedbacks = await reranking_service.recuperer_donnees_entrainement()

# 2. CrÃ©ation des paires d'entraÃ®nement
training_pairs = [
    {
        "texts": [query, document],
        "label": relevance_score  # 0.0 Ã  1.0
    }
    for feedback in feedbacks
]

# 3. Fine-tuning
model.fit(
    train_dataloader=train_dataloader,
    epochs=3,
    warmup_steps=warmup_steps,
    output_path="models/cross_encoder"
)

# 4. Sauvegarde automatique
# - models/cross_encoder/config.json
# - models/cross_encoder/pytorch_model.bin
# - models/cross_encoder/metadata.pkl
```

### HyperparamÃ¨tres

| ParamÃ¨tre | Valeur par dÃ©faut | Description |
|-----------|-------------------|-------------|
| `num_epochs` | 3 | Nombre d'Ã©poques |
| `batch_size` | 16 | Taille des batchs |
| `learning_rate` | 2e-5 | Taux d'apprentissage |
| `warmup_steps` | 10% du total | MontÃ©e progressive du LR |

## ğŸ“¡ API Endpoints

### 1. Recherche avec re-ranking

```http
POST /api/reranking/recherche-avec-reranking
Content-Type: application/json

{
  "question": "machine learning tutorial",
  "top_k_faiss": 50,
  "top_k_final": 10,
  "use_reranker": true
}
```

**RÃ©ponse**:
```json
{
  "question": "machine learning tutorial",
  "nb_resultats_faiss": 50,
  "nb_resultats_finaux": 10,
  "reranking_applique": true,
  "resultats": [
    {
      "resource_id": "507f...",
      "titre": "Introduction to Machine Learning",
      "url": "https://...",
      "source": "wikipedia",
      "faiss_score": 0.85,
      "reranking_score": 3.42,
      "final_score": 0.89,
      "rank": 1
    }
  ],
  "duree_recherche_ms": 125.5
}
```

### 2. Soumettre un feedback

```http
POST /api/reranking/feedback
Content-Type: application/json

{
  "query_id": "507f1f77bcf86cd799439011",
  "resource_id": "507f1f77bcf86cd799439012",
  "feedback_type": "like",
  "session_id": "session_123"
}
```

### 3. Statistiques des feedbacks

```http
GET /api/reranking/statistiques-feedback
```

**RÃ©ponse**:
```json
{
  "nb_feedbacks_total": 150,
  "nb_likes": 100,
  "nb_dislikes": 50,
  "nb_training_pairs": 150,
  "model_version": "finetuned_20240120_143000",
  "last_training_date": "2024-01-20T14:30:00"
}
```

### 4. Lancer le fine-tuning

```http
POST /api/reranking/fine-tune?num_epochs=3&batch_size=16&learning_rate=2e-5
```

âš ï¸ **Attention**: Cette opÃ©ration peut prendre plusieurs minutes selon le nombre de donnÃ©es.

### 5. PrÃ©dire un score de pertinence

```http
POST /api/reranking/predict-score?query=machine%20learning&document=Introduction%20to%20ML...
```

**RÃ©ponse**:
```json
{
  "status": "success",
  "query": "machine learning",
  "document": "Introduction to ML...",
  "raw_score": 3.42,
  "normalized_score": 0.91,
  "interpretation": "TrÃ¨s pertinent"
}
```

### 6. Informations sur le modÃ¨le

```http
GET /api/reranking/info-modele
```

## ğŸ”„ Workflow recommandÃ©

### Phase 1: DÃ©marrage (ModÃ¨le de base)

```
1. DÃ©marrer l'application
   â†’ ModÃ¨le de base chargÃ© automatiquement

2. Utiliser le re-ranking avec le modÃ¨le de base
   â†’ Bons rÃ©sultats gÃ©nÃ©riques

3. Collecter des feedbacks utilisateurs
   â†’ Like/Dislike sur les rÃ©sultats
```

### Phase 2: Collecte de donnÃ©es

```
4. Les utilisateurs interagissent avec le systÃ¨me
   â†’ Feedbacks sauvegardÃ©s automatiquement

5. Monitorer les statistiques
   GET /api/reranking/statistiques-feedback

6. Attendre d'avoir suffisamment de donnÃ©es
   â†’ Minimum 10, recommandÃ© 100+
```

### Phase 3: Fine-tuning

```
7. Lancer le fine-tuning
   POST /api/reranking/fine-tune

8. Le modÃ¨le s'adapte Ã  vos donnÃ©es
   â†’ 3-10 minutes selon la quantitÃ© de donnÃ©es

9. ModÃ¨le fine-tunÃ© sauvegardÃ© automatiquement
   â†’ models/cross_encoder/

10. Rechargement automatique du modÃ¨le fine-tunÃ©
    â†’ Meilleurs rÃ©sultats pour votre domaine
```

### Phase 4: AmÃ©lioration continue

```
11. Continuer Ã  collecter des feedbacks

12. Re-fine-tuner pÃ©riodiquement
    â†’ Tous les X nouveaux feedbacks
    â†’ Tous les X jours/semaines

13. Le modÃ¨le s'amÃ©liore progressivement
    â†’ Adaptation continue Ã  vos utilisateurs
```

## ğŸ“Š Scoring

### Score FAISS (similaritÃ© cosine)

- **Range**: 0 Ã  1
- **Calcul**: Produit scalaire des embeddings normalisÃ©s
- **InterprÃ©tation**: SimilaritÃ© sÃ©mantique gÃ©nÃ©rale

### Score Re-ranking (cross-encoder)

- **Range**: -âˆ Ã  +âˆ (typiquement -5 Ã  +5)
- **Calcul**: Output du classificateur BERT
- **Normalisation**: SigmoÃ¯de pour ramener Ã  [0, 1]

```python
score_normalized = 1 / (1 + exp(-raw_score))
```

### Score final combinÃ©

```python
final_score = Î± Ã— faiss_score + (1 - Î±) Ã— reranking_score_normalized
```

- **Î±** (alpha): Poids pour FAISS (par dÃ©faut: 0.3)
- **(1 - Î±)**: Poids pour re-ranking (par dÃ©faut: 0.7)

**Justification**: Le cross-encoder est plus prÃ©cis, on lui donne plus de poids.

## ğŸ¯ Cas d'usage

### 1. AmÃ©lioration de la prÃ©cision

**ProblÃ¨me**: FAISS retourne des rÃ©sultats similaires mais pas toujours pertinents.

**Solution**: Le cross-encoder affine en analysant la pertinence rÃ©elle.

### 2. Adaptation au domaine

**ProblÃ¨me**: ModÃ¨le gÃ©nÃ©rique pas optimal pour votre domaine spÃ©cifique.

**Solution**: Fine-tuning sur vos feedbacks utilisateurs.

### 3. Personnalisation

**ProblÃ¨me**: DiffÃ©rents utilisateurs ont des prÃ©fÃ©rences diffÃ©rentes.

**Solution**: Feedbacks par session/utilisateur â†’ modÃ¨le personnalisÃ©.

## âš¡ Performance

### Temps de rÃ©ponse

| Ã‰tape | Temps typique |
|-------|---------------|
| FAISS (50 candidats) | 1-5 ms |
| Cross-encoder (50 docs) | 50-200 ms |
| **Total** | **50-200 ms** |

### Optimisations possibles

1. **RÃ©duire les candidats**: 50 au lieu de 100
2. **Batch processing**: Traiter plusieurs requÃªtes ensemble
3. **GPU**: Utiliser un GPU pour le cross-encoder
4. **Caching**: Mettre en cache les scores frÃ©quents
5. **ModÃ¨le plus lÃ©ger**: Utiliser MiniLM-L-2 au lieu de L-6

## ğŸ› DÃ©pannage

### Le fine-tuning Ã©choue

**SymptÃ´me**: Erreur "Pas assez de donnÃ©es"

**Solution**: Collectez plus de feedbacks (minimum 10)

### ModÃ¨le ne s'amÃ©liore pas

**SymptÃ´me**: Pas de diffÃ©rence avant/aprÃ¨s fine-tuning

**Causes possibles**:
- Pas assez de donnÃ©es (< 100)
- DonnÃ©es de mauvaise qualitÃ©
- Feedbacks trop uniformes (tous likes ou tous dislikes)

**Solutions**:
- Collecter plus de feedbacks diversifiÃ©s
- VÃ©rifier la qualitÃ© des feedbacks
- Augmenter le nombre d'Ã©poques

### Re-ranking trop lent

**SymptÃ´me**: Temps de rÃ©ponse > 500ms

**Solutions**:
- RÃ©duire `top_k_faiss` (ex: 30 au lieu de 50)
- Utiliser un GPU
- DÃ©sactiver temporairement le re-ranking pour certaines requÃªtes

## ğŸ“ˆ MÃ©triques de qualitÃ©

### Avant/aprÃ¨s fine-tuning

Ã€ mesurer :
- **Precision@5**: Proportion de rÃ©sultats pertinents dans le top 5
- **NDCG@10**: Normalized Discounted Cumulative Gain
- **Click-through rate**: Taux de clics sur les rÃ©sultats
- **User satisfaction**: Ratio likes/(likes+dislikes)

## ğŸ”® Ã‰volutions futures

1. **ModÃ¨les multilingues**: Utiliser un cross-encoder FR/EN
2. **Contextualisation**: Prendre en compte l'historique utilisateur
3. **A/B Testing**: Comparer diffÃ©rents modÃ¨les
4. **Apprentissage continu**: Re-training automatique
5. **Ensemble methods**: Combiner plusieurs cross-encoders

## ğŸ“– RÃ©fÃ©rences

- [Sentence-Transformers Documentation](https://www.sbert.net/)
- [MS MARCO Dataset](https://microsoft.github.io/msmarco/)
- [Cross-Encoders for Semantic Search](https://www.sbert.net/examples/applications/cross-encoder/README.html)
- [BERT Paper](https://arxiv.org/abs/1810.04805)

## ğŸ“ Concepts clÃ©s

### Cross-Encoder vs Bi-Encoder

**Bi-Encoder** (FAISS):
```
Query    â†’ Encoderâ‚ â†’ Embeddingâ‚ â”€â”
                                   â”œâ”€ SimilaritÃ©
Document â†’ Encoderâ‚‚ â†’ Embeddingâ‚‚ â”€â”˜
```

**Cross-Encoder** (Re-ranking):
```
[Query + Document] â†’ BERT â†’ Classificateur â†’ Score
```

### Transfer Learning

1. **PrÃ©-entraÃ®nement**: ModÃ¨le entraÃ®nÃ© sur MS MARCO (millions d'exemples)
2. **Fine-tuning**: Adaptation sur vos donnÃ©es (centaines/milliers d'exemples)
3. **Avantage**: Peu de donnÃ©es nÃ©cessaires grÃ¢ce au prÃ©-entraÃ®nement

---

**Date de crÃ©ation**: 2024-01-20  
**Version**: 1.0.0  
**Statut**: âœ… Production Ready
