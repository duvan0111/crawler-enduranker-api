# Workflow Global de Traitement - EduRanker API

## Vue d'ensemble

Le workflow global permet de traiter une requ√™te utilisateur de bout en bout, depuis la collecte de ressources jusqu'au retour des 10 meilleures ressources √©ducatives.

## Architecture du Workflow

Le workflow se compose de 6 √©tapes principales :

### 1. Sauvegarde de la Question
- La question de l'utilisateur est sauvegard√©e dans MongoDB
- G√©n√©ration automatique d'un embedding vectoriel (384 dimensions)
- D√©tection de la langue

### 2. Crawling des Sources
- Collecte de ressources depuis :
  - **Wikipedia** : Articles √©ducatifs (FR/EN)
  - **GitHub** : Repositories et README
  - **Medium** : Articles de blog
- G√©n√©ration d'embeddings pour chaque ressource
- Sauvegarde dans MongoDB

### 3. Reconstruction de l'Index FAISS
- Reconstruction de l'index FAISS avec toutes les ressources
- Indexation des embeddings pour la recherche s√©mantique rapide
- Sauvegarde de l'index sur disque

### 4. Recherche S√©mantique (FAISS)
- Recherche des ressources les plus pertinentes
- Utilisation de la similarit√© cosine
- Retour des top K r√©sultats (par d√©faut 50)

### 5. Re-ranking avec Cross-Encoder
- Affinage du classement avec un mod√®le BERT cross-encoder
- Score de pertinence plus pr√©cis
- R√©duction au top 10 final

### 6. Sauvegarde des Inf√©rences
- Sauvegarde des r√©sultats dans la collection `inference`
- Tracking des scores pour chaque ressource
- Utilisation pour le fine-tuning du mod√®le

## Endpoint API

### POST `/api/workflow/process`

Traite une requ√™te compl√®te et retourne le top 10 des meilleures ressources.

#### Requ√™te

```json
{
  "question": "Comment apprendre le machine learning ?",
  "max_par_site": 15,
  "sources": ["wikipedia", "github", "medium"],
  "langues": ["fr", "en"],
  "top_k_faiss": 50,
  "top_k_final": 10
}
```

#### Param√®tres

| Param√®tre | Type | D√©faut | Description |
|-----------|------|--------|-------------|
| `question` | string | **requis** | Question de l'utilisateur |
| `max_par_site` | int | 15 | Nombre max de r√©sultats par site |
| `sources` | array | ["wikipedia", "github", "medium"] | Sources √† crawler |
| `langues` | array | ["fr", "en"] | Langues pour Wikipedia |
| `top_k_faiss` | int | 50 | Nombre de r√©sultats FAISS |
| `top_k_final` | int | 10 | Nombre de r√©sultats finaux |

#### R√©ponse

```json
{
  "question": "Comment apprendre le machine learning ?",
  "id_requete": "507f1f77bcf86cd799439011",
  "total_crawle": 45,
  "total_resultats_faiss": 50,
  "total_resultats_final": 10,
  "duree_crawl_secondes": 12.5,
  "duree_recherche_secondes": 0.3,
  "duree_reranking_secondes": 1.2,
  "duree_totale_secondes": 14.0,
  "resultats": [
    {
      "titre": "Introduction au Machine Learning",
      "url": "https://example.com/ml-intro",
      "auteur": "John Doe",
      "date": "2024-01-15",
      "score_faiss": 0.85,
      "score_reranking": 0.92,
      "score_final": 0.89,
      "mots_cles": ["machine learning", "IA", "√©ducation"],
      "source": "wikipedia",
      "id_inference": "507f1f77bcf86cd799439012"
    }
  ],
  "sources_crawlees": ["wikipedia", "github", "medium"],
  "erreurs": []
}
```

#### Format des R√©sultats

Chaque ressource dans `resultats` contient :

| Champ | Type | Description |
|-------|------|-------------|
| `titre` | string | Titre de la ressource |
| `url` | string | URL de la ressource |
| `auteur` | string | Auteur (si disponible) |
| `date` | string | Date de publication |
| `score_faiss` | float | Score de similarit√© FAISS (0-1) |
| `score_reranking` | float | Score du cross-encoder |
| `score_final` | float | Score combin√© (0.3√óFAISS + 0.7√óreranking) |
| `mots_cles` | array | Mots-cl√©s de la ressource |
| `source` | string | Source (wikipedia/github/medium) |
| `id_inference` | string | ID de l'inf√©rence MongoDB |

## Exemples d'Utilisation

### Exemple 1 : Requ√™te Simple

```bash
curl -X POST "http://localhost:8000/api/workflow/process" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Comment apprendre Python ?"
  }'
```

### Exemple 2 : Requ√™te Personnalis√©e

```bash
curl -X POST "http://localhost:8000/api/workflow/process" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Deep learning for computer vision",
    "max_par_site": 20,
    "sources": ["github", "medium"],
    "langues": ["en"],
    "top_k_faiss": 100,
    "top_k_final": 15
  }'
```

### Exemple 3 : Avec Python

```python
import requests

response = requests.post(
    "http://localhost:8000/api/workflow/process",
    json={
        "question": "Comment utiliser TensorFlow ?",
        "max_par_site": 15,
        "sources": ["wikipedia", "github"],
        "langues": ["fr", "en"],
        "top_k_faiss": 50,
        "top_k_final": 10
    }
)

data = response.json()
print(f"Nombre de r√©sultats : {data['total_resultats_final']}")

for i, ressource in enumerate(data['resultats'], 1):
    print(f"\n{i}. {ressource['titre']}")
    print(f"   URL: {ressource['url']}")
    print(f"   Score: {ressource['score_final']:.3f}")
    print(f"   Source: {ressource['source']}")
```

## Performances

### Temps d'Ex√©cution Typiques

| √âtape | Dur√©e Moyenne |
|-------|---------------|
| Sauvegarde question | < 0.1s |
| Crawling | 10-30s |
| Reconstruction index | 1-5s |
| Recherche FAISS | 0.1-0.5s |
| Re-ranking | 1-3s |
| **Total** | **12-40s** |

### Optimisations

- **Cache** : Les ressources sont r√©utilis√©es entre les requ√™tes
- **Index FAISS** : Recherche ultra-rapide (m√™me avec 100k+ ressources)
- **Parall√©lisation** : Crawling des sources en parall√®le
- **Fine-tuning** : Le mod√®le s'am√©liore avec les feedbacks

## Flux de Donn√©es

```
Question Utilisateur
       ‚Üì
[1] Sauvegarde + Embedding
       ‚Üì
[2] Crawling Multi-Sources ‚Üí MongoDB
       ‚Üì
[3] Index FAISS ‚Üê Embeddings
       ‚Üì
[4] Recherche FAISS ‚Üí Top 50
       ‚Üì
[5] Cross-Encoder ‚Üí Top 10
       ‚Üì
[6] Sauvegarde Inf√©rences
       ‚Üì
   Top 10 R√©sultats
```

## Gestion des Erreurs

Le workflow est robuste et continue m√™me si certaines √©tapes √©chouent :

- **Erreur crawling** : Continue avec les sources disponibles
- **Erreur index FAISS** : Utilise l'index existant
- **Erreur re-ranking** : Retourne les r√©sultats FAISS bruts
- **Toutes les erreurs** : Sont list√©es dans `erreurs[]`

## Monitoring

### Health Check

```bash
curl http://localhost:8000/api/workflow/health
```

### Logs

Les logs d√©taill√©s sont disponibles dans la console :

```
üöÄ D√©but du workflow pour la question: Comment apprendre le ML ?
üìù √âTAPE 1/6: Sauvegarde de la question utilisateur...
‚úÖ Question sauvegard√©e (ID: 507f...)
üï∑Ô∏è  √âTAPE 2/6: Lancement du crawling...
‚úÖ Crawling termin√©: 45 ressources en 12.50s
üîÑ √âTAPE 3/6: Reconstruction de l'index FAISS...
‚úÖ Index FAISS reconstruit: 1234 vecteurs
üîç √âTAPE 4/6: Recherche s√©mantique avec FAISS...
‚úÖ Recherche FAISS: 50 r√©sultats en 0.30s
üéØ √âTAPE 5/6: Re-ranking avec cross-encoder...
‚úÖ Re-ranking termin√©: 10 r√©sultats en 1.20s
üíæ √âTAPE 6/6: Sauvegarde des inf√©rences...
‚úÖ Workflow termin√© en 14.00s
üìä R√©sultats: 10 ressources finales
```

## Int√©gration Frontend

Le format de r√©ponse est optimis√© pour l'affichage frontend :

```javascript
// Affichage des r√©sultats
response.resultats.forEach((ressource, index) => {
  console.log(`${index + 1}. ${ressource.titre}`);
  console.log(`   Score: ${ressource.score_final.toFixed(2)}`);
  console.log(`   Source: ${ressource.source}`);
  
  // Badge de qualit√© bas√© sur le score
  const badge = ressource.score_final > 0.8 ? 'üèÜ' : 
                ressource.score_final > 0.6 ? '‚≠ê' : '‚úì';
  console.log(`   ${badge} ${ressource.url}`);
});

// Statistiques
console.log(`\nStatistiques:`);
console.log(`- Ressources crawl√©es: ${response.total_crawle}`);
console.log(`- Temps total: ${response.duree_totale_secondes}s`);
console.log(`- Sources: ${response.sources_crawlees.join(', ')}`);
```

## Limites et Consid√©rations

### Limites Techniques

- **Max r√©sultats par site** : 50 (pour √©viter le rate limiting)
- **Timeout** : 60s par source
- **Index FAISS** : Capacit√© illimit√©e (mais performance d√©grad√©e > 1M vecteurs)

### Consid√©rations

- Le crawling peut √™tre lent (10-30s) selon les sources
- Les r√©sultats d√©pendent de la qualit√© des sources
- Le re-ranking n√©cessite un GPU pour de meilleures performances
- Les embeddings occupent ~1.5KB par ressource

## Prochaines √âtapes

1. **Utiliser le workflow** : Testez avec diff√©rentes questions
2. **Collecter des feedbacks** : Utilisez `/api/reranking/feedback`
3. **Fine-tuner le mod√®le** : Ex√©cutez le notebook de fine-tuning
4. **Am√©liorer les scores** : Le mod√®le s'am√©liore avec l'usage

## Support

Pour toute question ou probl√®me :
- üìö Documentation : `/docs`
- üîç API Docs : `http://localhost:8000/docs`
- üí° Exemples : Voir les notebooks dans `/notebooks`
