#!/usr/bin/env python3
"""
Script d'analyse des inf√©rences pour √©valuer les performances du syst√®me.
G√©n√®re des statistiques et visualisations sur les recommandations.
"""

import os
from pymongo import MongoClient
from datetime import datetime, timedelta
from collections import defaultdict

def analyze_inferences():
    """Analyse les inf√©rences et g√©n√®re des statistiques"""
    
    # Configuration
    mongodb_url = os.getenv("MONGODB_URL", "mongodb://localhost:27017")
    mongodb_db = os.getenv("MONGODB_DB_NAME", "eduranker_db")
    
    print(f"üîå Connexion √† MongoDB: {mongodb_url}")
    print(f"üìÅ Base de donn√©es: {mongodb_db}\n")
    
    try:
        client = MongoClient(mongodb_url)
        db = client[mongodb_db]
        inference_col = db["inference"]
        
        # 1. Statistiques g√©n√©rales
        print("=" * 60)
        print("üìä STATISTIQUES G√âN√âRALES")
        print("=" * 60)
        
        total = inference_col.count_documents({})
        print(f"Total d'inf√©rences: {total}")
        
        if total == 0:
            print("\n‚ö†Ô∏è  Aucune inf√©rence trouv√©e dans la base de donn√©es.")
            print("   Effectuez des recherches avec re-ranking pour g√©n√©rer des donn√©es.\n")
            client.close()
            return
        
        # Nombre de requ√™tes uniques
        unique_queries = len(inference_col.distinct("user_query_id"))
        print(f"Requ√™tes utilisateur uniques: {unique_queries}")
        
        # Nombre de ressources uniques recommand√©es
        unique_resources = len(inference_col.distinct("resource_id"))
        print(f"Ressources uniques recommand√©es: {unique_resources}")
        
        # Moyenne de recommandations par requ√™te
        avg_per_query = total / unique_queries if unique_queries > 0 else 0
        print(f"Moyenne de recommandations par requ√™te: {avg_per_query:.1f}")
        
        # 2. Analyse des scores
        print("\n" + "=" * 60)
        print("üìà ANALYSE DES SCORES")
        print("=" * 60)
        
        pipeline_scores = [
            {
                "$group": {
                    "_id": None,
                    "avg_faiss": {"$avg": "$faiss_score"},
                    "avg_reranking": {"$avg": "$reranking_score"},
                    "avg_final": {"$avg": "$final_score"},
                    "min_final": {"$min": "$final_score"},
                    "max_final": {"$max": "$final_score"}
                }
            }
        ]
        
        scores_result = list(inference_col.aggregate(pipeline_scores))
        if scores_result:
            stats = scores_result[0]
            print(f"Score FAISS moyen: {stats['avg_faiss']:.4f}")
            print(f"Score Re-ranking moyen: {stats.get('avg_reranking', 'N/A')}")
            print(f"Score final moyen: {stats['avg_final']:.4f}")
            print(f"Score final min: {stats['min_final']:.4f}")
            print(f"Score final max: {stats['max_final']:.4f}")
        
        # 3. Distribution par rang
        print("\n" + "=" * 60)
        print("üèÜ DISTRIBUTION PAR RANG")
        print("=" * 60)
        
        pipeline_ranks = [
            {"$group": {"_id": "$rank", "count": {"$sum": 1}}},
            {"$sort": {"_id": 1}},
            {"$limit": 10}
        ]
        
        rank_distribution = list(inference_col.aggregate(pipeline_ranks))
        for item in rank_distribution:
            rank = item['_id']
            count = item['count']
            percentage = (count / total) * 100
            bar = "‚ñà" * int(percentage / 2)
            print(f"Rang {rank:2d}: {bar} {count:5d} ({percentage:5.1f}%)")
        
        # 4. Analyse des feedbacks
        print("\n" + "=" * 60)
        print("üí¨ ANALYSE DES FEEDBACKS")
        print("=" * 60)
        
        with_feedback = inference_col.count_documents({"feedback": {"$ne": None}})
        feedback_rate = (with_feedback / total) * 100
        print(f"Inf√©rences avec feedback: {with_feedback} / {total} ({feedback_rate:.1f}%)")
        
        if with_feedback > 0:
            print("\nR√©partition des feedbacks:")
            pipeline_feedback = [
                {"$match": {"feedback": {"$ne": None}}},
                {"$group": {"_id": "$feedback", "count": {"$sum": 1}}},
                {"$sort": {"count": -1}}
            ]
            
            feedback_dist = list(inference_col.aggregate(pipeline_feedback))
            for item in feedback_dist:
                fb_type = item['_id']
                count = item['count']
                percentage = (count / with_feedback) * 100
                emoji = {"like": "üëç", "dislike": "üëé", "click": "üñ±Ô∏è", "view": "üëÅÔ∏è"}.get(fb_type, "‚ùì")
                print(f"  {emoji} {fb_type}: {count} ({percentage:.1f}%)")
            
            # Taux de satisfaction (likes / (likes + dislikes))
            likes = inference_col.count_documents({"feedback": "like"})
            dislikes = inference_col.count_documents({"feedback": "dislike"})
            if likes + dislikes > 0:
                satisfaction = (likes / (likes + dislikes)) * 100
                print(f"\nüòä Taux de satisfaction: {satisfaction:.1f}%")
        
        # 5. Position moyenne des feedbacks
        print("\n" + "=" * 60)
        print("üìç POSITION MOYENNE DES FEEDBACKS")
        print("=" * 60)
        
        pipeline_feedback_rank = [
            {"$match": {"feedback": {"$ne": None}}},
            {"$group": {
                "_id": "$feedback",
                "avg_rank": {"$avg": "$rank"},
                "min_rank": {"$min": "$rank"},
                "max_rank": {"$max": "$rank"}
            }}
        ]
        
        feedback_ranks = list(inference_col.aggregate(pipeline_feedback_rank))
        for item in feedback_ranks:
            fb_type = item['_id']
            avg_rank = item['avg_rank']
            min_rank = item['min_rank']
            max_rank = item['max_rank']
            emoji = {"like": "üëç", "dislike": "üëé", "click": "üñ±Ô∏è", "view": "üëÅÔ∏è"}.get(fb_type, "‚ùì")
            print(f"{emoji} {fb_type}: rang moyen {avg_rank:.1f} (min: {min_rank}, max: {max_rank})")
        
        # 6. Impact du re-ranking
        print("\n" + "=" * 60)
        print("üîÑ IMPACT DU RE-RANKING")
        print("=" * 60)
        
        with_reranking = inference_col.count_documents({"reranking_score": {"$ne": None}})
        print(f"Inf√©rences avec re-ranking: {with_reranking} / {total}")
        
        if with_reranking > 0:
            pipeline_improvement = [
                {"$match": {"reranking_score": {"$ne": None}}},
                {"$project": {
                    "improvement": {"$subtract": ["$final_score", "$faiss_score"]}
                }},
                {"$group": {
                    "_id": None,
                    "avg_improvement": {"$avg": "$improvement"},
                    "positive_count": {
                        "$sum": {"$cond": [{"$gt": ["$improvement", 0]}, 1, 0]}
                    },
                    "total": {"$sum": 1}
                }}
            ]
            
            improvement_result = list(inference_col.aggregate(pipeline_improvement))
            if improvement_result:
                stats = improvement_result[0]
                avg_imp = stats['avg_improvement']
                pos_count = stats['positive_count']
                total_rerank = stats['total']
                pos_rate = (pos_count / total_rerank) * 100
                
                print(f"Am√©lioration moyenne du score: {avg_imp:+.4f}")
                print(f"Am√©liorations positives: {pos_count} / {total_rerank} ({pos_rate:.1f}%)")
        
        # 7. Top ressources recommand√©es
        print("\n" + "=" * 60)
        print("üåü TOP 10 RESSOURCES RECOMMAND√âES")
        print("=" * 60)
        
        pipeline_top = [
            {"$group": {
                "_id": "$resource_id",
                "count": {"$sum": 1},
                "avg_rank": {"$avg": "$rank"},
                "avg_score": {"$avg": "$final_score"},
                "feedbacks": {"$push": "$feedback"}
            }},
            {"$sort": {"count": -1}},
            {"$limit": 10}
        ]
        
        top_resources = list(inference_col.aggregate(pipeline_top))
        for i, item in enumerate(top_resources, 1):
            resource_id = item['_id']
            count = item['count']
            avg_rank = item['avg_rank']
            avg_score = item['avg_score']
            feedbacks = [f for f in item['feedbacks'] if f is not None]
            fb_count = len(feedbacks)
            
            print(f"{i:2d}. Ressource {resource_id}")
            print(f"    Recommand√©e {count} fois (rang moyen: {avg_rank:.1f}, score: {avg_score:.3f})")
            if fb_count > 0:
                print(f"    Feedbacks: {fb_count}")
        
        client.close()
        print("\n" + "=" * 60)
        print("‚úÖ Analyse termin√©e!")
        print("=" * 60 + "\n")
        
    except Exception as e:
        print(f"\n‚ùå Erreur: {e}\n")

if __name__ == "__main__":
    analyze_inferences()
