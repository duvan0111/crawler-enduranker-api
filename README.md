# EduRanker Crawler API

Backend FastAPI pour le projet EduRanker avec systÃ¨me de crawling intÃ©grÃ©.

## ğŸ¯ FonctionnalitÃ©s

- **API REST complÃ¨te** avec FastAPI
- **Crawler de ressources Ã©ducatives** depuis Wikipedia, GitHub, Medium
- **Base de donnÃ©es MongoDB** pour le stockage
- **Documentation interactive** avec Swagger UI
- **Architecture MVC** (Models, Views, Controllers)

## ğŸ“ Structure du projet

```
crawler-enduranker-api/
â”œâ”€â”€ public/                    # Fichiers statiques
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ crawler/              # SystÃ¨me de crawling Scrapy
â”‚   â”‚   â”œâ”€â”€ spiders/          # Spiders Wikipedia, GitHub, Medium
â”‚   â”‚   â””â”€â”€ utils/            # Utilitaires de crawling
â”‚   â”œâ”€â”€ controllers/          # Logique de contrÃ´le
â”‚   â”œâ”€â”€ models/               # ModÃ¨les Pydantic
â”‚   â”œâ”€â”€ routes/               # Routes API
â”‚   â”œâ”€â”€ services/             # Logique mÃ©tier
â”‚   â””â”€â”€ database.py           # Configuration MongoDB
â”œâ”€â”€ venv/                     # Environnement virtuel
â”œâ”€â”€ main.py                   # Point d'entrÃ©e
â”œâ”€â”€ scrapy.cfg               # Configuration Scrapy
â”œâ”€â”€ requirements.txt         # DÃ©pendances
â””â”€â”€ .env                     # Variables d'environnement
```

## Installation

1. CrÃ©er et activer l'environnement virtuel :
```bash
python3 -m venv venv
source venv/bin/activate  # Sur Linux/Mac
# ou
venv\Scripts\activate  # Sur Windows
```

2. Installer les dÃ©pendances :
```bash
pip install -r requirements.txt
```

3. Configurer les variables d'environnement :
```bash
cp .env.example .env
# Puis Ã©diter le fichier .env selon votre configuration
```

## Configuration de MongoDB

Assurez-vous que MongoDB est installÃ© et en cours d'exÃ©cution localement :

```bash
# VÃ©rifier si MongoDB est en cours d'exÃ©cution
sudo systemctl status mongod

# DÃ©marrer MongoDB si nÃ©cessaire
sudo systemctl start mongod

# Activer MongoDB au dÃ©marrage
sudo systemctl enable mongod
```

Par dÃ©faut, l'application se connecte Ã  `mongodb://localhost:27017` avec la base de donnÃ©es `eduranker_db`.
Vous pouvez modifier ces valeurs dans le fichier `.env` :

```env
MONGODB_URL=mongodb://localhost:27017
MONGODB_DB_NAME=eduranker_db
```

## Lancement

```bash
python main.py
# ou
uvicorn main:app --reload
```

L'API sera accessible sur `http://localhost:8000`

La documentation interactive sera disponible sur :
- Swagger UI : `http://localhost:8000/docs`
- ReDoc : `http://localhost:8000/redoc`

## ğŸš€ Utilisation de l'API Crawler

### Collecter des ressources Ã©ducatives

La route principale vous permet d'envoyer une question et de recevoir une liste d'articles/ressources :

```bash
curl -X POST "http://localhost:8000/api/crawler/collect" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "machine learning en Ã©ducation"
  }'
```

**Avec paramÃ¨tres personnalisÃ©s :**

```bash
curl -X POST "http://localhost:8000/api/crawler/collect" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "deep learning",
    "max_par_site": 10,
    "sources": ["wikipedia", "github"],
    "langues": ["fr", "en"]
  }'
```

### Rechercher dans les ressources existantes

```bash
curl -X POST "http://localhost:8000/api/crawler/search" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "machine learning",
    "limite": 20
  }'
```

### Scripts de test

Pour tester rapidement l'API :

```bash
# Test de l'API CRUD de base
./test_api.sh

# Test de l'API Crawler
./test_crawler_api.sh
```

## Test de la connexion MongoDB

Pour vÃ©rifier que MongoDB fonctionne correctement :

```bash
# Test de connexion MongoDB
mongosh

# Dans le shell MongoDB
show dbs
use eduranker_db
show collections
```
