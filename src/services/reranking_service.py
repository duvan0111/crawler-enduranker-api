"""
Service de Re-ranking avec Cross-Encoder pour affiner le classement des r√©sultats FAISS.
Ce service utilise un mod√®le BERT cross-encoder qui peut √™tre fine-tun√© sur les feedbacks utilisateurs.
"""

import logging
import pickle
import os
import time
from pathlib import Path
from typing import List, Dict, Tuple, Optional
import numpy as np
import pymongo
from datetime import datetime
from sentence_transformers import CrossEncoder
import torch

from src.models.reranking_model import (
    UserFeedbackModel,
    TrainingPairModel,
    FineTuningStatsModel,
    InferenceModel
)

logger = logging.getLogger(__name__)


class RerankingService:
    """Service pour le re-ranking avec cross-encoder et fine-tuning"""
    
    def __init__(
        self, 
        mongodb_url: str, 
        mongodb_db: str, 
        model_name: str = "cross-encoder/ms-marco-MiniLM-L-6-v2",
        model_path: str = "models/cross_encoder"
    ):
        """
        Initialise le service de re-ranking
        
        Args:
            mongodb_url: URL de connexion MongoDB
            mongodb_db: Nom de la base de donn√©es
            model_name: Nom du mod√®le cross-encoder de base
            model_path: Chemin pour sauvegarder le mod√®le fine-tun√©
        """
        self.mongodb_url = mongodb_url
        self.mongodb_db = mongodb_db
        self.feedback_collection = "user_feedbacks"
        self.inference_collection = "inference"
        self.model_path = model_path
        self.base_model_name = model_name
        
        # Cr√©er le dossier pour le mod√®le s'il n'existe pas
        Path(model_path).mkdir(parents=True, exist_ok=True)
        
        # Charger le cross-encoder
        self._charger_modele()
        
    def _charger_modele(self):
        """Charge le mod√®le cross-encoder (fine-tun√© ou de base)"""
        try:
            # Essayer de charger un mod√®le fine-tun√©
            if os.path.exists(os.path.join(self.model_path, "config.json")):
                logger.info(f"üì• Chargement du mod√®le fine-tun√© depuis {self.model_path}...")
                self.cross_encoder = CrossEncoder(self.model_path)
                logger.info("‚úÖ Mod√®le fine-tun√© charg√© avec succ√®s")
            else:
                # Charger le mod√®le de base
                logger.info(f"üì• Chargement du mod√®le de base {self.base_model_name}...")
                self.cross_encoder = CrossEncoder(self.base_model_name)
                logger.info("‚úÖ Mod√®le de base charg√© avec succ√®s")
                
        except Exception as e:
            logger.error(f"‚ùå Erreur chargement mod√®le: {e}")
            logger.warning("‚ö†Ô∏è  Le mod√®le cross-encoder n'a pas pu √™tre charg√©.")
            logger.warning("‚ö†Ô∏è  Le service fonctionnera en mode d√©grad√© (sans re-ranking).")
            logger.warning("‚ö†Ô∏è  Solutions possibles :")
            logger.warning("    1. Augmenter le timeout : export HF_HUB_DOWNLOAD_TIMEOUT=600")
            logger.warning("    2. T√©l√©charger le mod√®le manuellement : huggingface-cli download cross-encoder/ms-marco-MiniLM-L-6-v2")
            logger.warning("    3. Utiliser un miroir : export HF_ENDPOINT=https://hf-mirror.com")
            logger.warning("    4. Consulter TROUBLESHOOTING.md pour plus de solutions")
            self.cross_encoder = None  # Mode d√©grad√©
    
    async def reranker_resultats(
        self,
        question: str,
        resultats_faiss: List[Dict],
        top_k: int = 10
    ) -> List[Dict]:
        """
        Re-classe les r√©sultats FAISS en utilisant le cross-encoder
        
        Args:
            question: Question de l'utilisateur
            resultats_faiss: R√©sultats de la recherche FAISS
            top_k: Nombre de r√©sultats finaux √† retourner
            
        Returns:
            Liste de r√©sultats re-class√©s avec scores
        """
        if not resultats_faiss:
            return []
        
        # Mode d√©grad√© : si le mod√®le n'est pas charg√©, retourner les r√©sultats FAISS sans re-ranking
        if self.cross_encoder is None:
            logger.warning("‚ö†Ô∏è  Cross-encoder non disponible, retour des r√©sultats FAISS sans re-ranking")
            resultats_tries = resultats_faiss[:top_k]
            for i, res in enumerate(resultats_tries, 1):
                res['rank'] = i
                res['faiss_score'] = res.get('score_similarite', 0.0)
                res['reranking_score'] = None
                res['final_score'] = res['faiss_score']
            return resultats_tries
        
        try:
            logger.info(f"üîÑ Re-ranking de {len(resultats_faiss)} r√©sultats avec cross-encoder...")
            
            # Pr√©parer les paires (question, document)
            paires = []
            for res in resultats_faiss:
                # Cr√©er un texte repr√©sentatif du document
                doc_text = self._creer_texte_document(res)
                paires.append([question, doc_text])
            
            # Pr√©dire les scores avec le cross-encoder
            scores = self.cross_encoder.predict(paires, show_progress_bar=False)
            
            # Ajouter les scores aux r√©sultats
            for i, res in enumerate(resultats_faiss):
                res['reranking_score'] = float(scores[i])
                res['faiss_score'] = res.get('score_similarite', 0.0)
                # Score final combin√© (moyenne pond√©r√©e)
                res['final_score'] = self._calculer_score_final(
                    res['faiss_score'], 
                    res['reranking_score']
                )
            
            # Trier par score final d√©croissant
            resultats_tries = sorted(
                resultats_faiss, 
                key=lambda x: x['final_score'], 
                reverse=True
            )
            
            # Retourner les top_k meilleurs
            resultats_finaux = resultats_tries[:top_k]
            
            # Ajouter le rang
            for i, res in enumerate(resultats_finaux, 1):
                res['rank'] = i
            
            logger.info(f"‚úÖ Re-ranking termin√©: {len(resultats_finaux)} r√©sultats retourn√©s")
            return resultats_finaux
            
        except Exception as e:
            logger.error(f"‚ùå Erreur re-ranking: {e}")
            # En cas d'erreur, retourner les r√©sultats FAISS originaux
            return resultats_faiss[:top_k]
    
    def _creer_texte_document(self, ressource: Dict) -> str:
        """
        Cr√©e un texte repr√©sentatif du document pour le cross-encoder
        
        Args:
            ressource: Dictionnaire de la ressource
            
        Returns:
            Texte concat√©n√© (titre + extrait de texte)
        """
        titre = ressource.get('titre', '')
        texte = ressource.get('texte', '')
        
        # Limiter la longueur du texte pour le cross-encoder (max 512 tokens)
        # Approximation: 1 token ‚âà 4 caract√®res
        max_chars = 1500
        
        if texte and len(texte) > max_chars:
            texte = texte[:max_chars] + "..."
        
        # Combiner titre et texte
        doc_text = f"{titre}. {texte}" if titre and texte else titre or texte
        
        return doc_text
    
    def _calculer_score_final(
        self, 
        faiss_score: float, 
        reranking_score: float,
        alpha: float = 0.3
    ) -> float:
        """
        Calcule le score final combin√©
        
        Args:
            faiss_score: Score de similarit√© FAISS (0-1)
            reranking_score: Score du cross-encoder (-inf, +inf, typiquement -5 √† 5)
            alpha: Poids pour FAISS (1-alpha pour reranking)
            
        Returns:
            Score final combin√©
        """
        # Normaliser le score de reranking avec sigmo√Øde
        reranking_norm = 1 / (1 + np.exp(-reranking_score))
        
        # Combiner les scores
        final_score = alpha * faiss_score + (1 - alpha) * reranking_norm
        
        return float(final_score)
    
    async def sauvegarder_inference(
        self,
        user_query_id: str,
        resource_id: str,
        faiss_score: float,
        reranking_score: Optional[float],
        final_score: float,
        rank: int,
        session_id: Optional[str] = None
    ) -> Dict:
        """
        Sauvegarde une inf√©rence (recommandation) dans MongoDB
        
        Args:
            user_query_id: ID de la requ√™te utilisateur
            resource_id: ID de la ressource recommand√©e
            faiss_score: Score FAISS
            reranking_score: Score du cross-encoder (peut √™tre None)
            final_score: Score final combin√©
            rank: Position dans le classement
            session_id: ID de session optionnel
            
        Returns:
            Dictionnaire avec le statut
        """
        try:
            client = pymongo.MongoClient(self.mongodb_url)
            db = client[self.mongodb_db]
            inference_col = db[self.inference_collection]
            
            # Cr√©er l'inf√©rence
            inference = {
                "user_query_id": user_query_id,
                "resource_id": resource_id,
                "faiss_score": faiss_score,
                "reranking_score": reranking_score,
                "final_score": final_score,
                "rank": rank,
                "feedback": None,  # Initialement √† null
                "date_inference": datetime.now(),
                "session_id": session_id,
                "metadata": {}
            }
            
            # Sauvegarder dans MongoDB
            result = inference_col.insert_one(inference)
            
            client.close()
            
            logger.debug(f"üíæ Inf√©rence sauvegard√©e: rank {rank} pour requ√™te {user_query_id}")
            
            return {
                "status": "success",
                "inference_id": str(result.inserted_id)
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erreur sauvegarde inf√©rence: {e}")
            return {
                "status": "error",
                "message": str(e)
            }
    
    async def sauvegarder_feedback(
        self,
        inference_id: str,
        feedback_type: str
    ) -> Dict:
        """
        Met √† jour le feedback d'une inf√©rence
        
        Args:
            inference_id: ID de l'inf√©rence
            feedback_type: Type de feedback (like, dislike, click, view)
            
        Returns:
            Dictionnaire avec le statut
        """
        try:
            from bson import ObjectId
            
            # Se connecter √† MongoDB
            client = pymongo.MongoClient(self.mongodb_url)
            db = client[self.mongodb_db]
            inference_col = db[self.inference_collection]
            
            # V√©rifier que l'inf√©rence existe
            inference = inference_col.find_one({"_id": ObjectId(inference_id)})
            
            if not inference:
                client.close()
                return {
                    "status": "error",
                    "message": f"Inf√©rence {inference_id} introuvable"
                }
            
            # Mettre √† jour le feedback dans l'inf√©rence
            result = inference_col.update_one(
                {"_id": ObjectId(inference_id)},
                {
                    "$set": {
                        "feedback": feedback_type,
                        "date_feedback": datetime.now()
                    }
                }
            )
            
            # Sauvegarder aussi dans la collection user_feedbacks pour historique
            # feedback_col = db[self.feedback_collection]
            # feedback_doc = {
            #     "inference_id": inference_id,
            #     "user_query_id": inference.get("user_query_id"),
            #     "resource_id": inference.get("resource_id"),
            #     "feedback_type": feedback_type,
            #     "relevance_score": 1.0 if feedback_type == "like" else 0.0 if feedback_type == "dislike" else 0.5,
            #     "session_id": inference.get("session_id"),
            #     "date_feedback": datetime.now(),
            #     "metadata": {}
            # }
            # feedback_result = feedback_col.insert_one(feedback_doc)
            
            client.close()
            
            if result.modified_count > 0:
                logger.info(f"üíæ Feedback '{feedback_type}' sauvegard√© pour inf√©rence {inference_id}")
                return {
                    "status": "success",
                    "inference_id": inference_id,
                    # "feedback_id": str(feedback_result.inserted_id),
                    "message": "Feedback enregistr√© avec succ√®s"
                }
            else:
                return {
                    "status": "error",
                    "message": "Aucune modification effectu√©e"
                }
            
        except Exception as e:
            logger.error(f"‚ùå Erreur sauvegarde feedback: {e}")
            return {
                "status": "error",
                "message": str(e)
            }
    
    async def recuperer_donnees_entrainement(self) -> List[TrainingPairModel]:
        """
        R√©cup√®re les paires d'entra√Ænement depuis les feedbacks
        
        Returns:
            Liste de paires (query, document, label)
        """
        try:
            client = pymongo.MongoClient(self.mongodb_url)
            db = client[self.mongodb_db]
            feedback_col = db[self.feedback_collection]
            
            # R√©cup√©rer tous les feedbacks avec like/dislike
            feedbacks = list(feedback_col.find({
                "feedback_type": {"$in": ["like", "dislike"]}
            }))
            
            client.close()
            
            # Cr√©er les paires d'entra√Ænement
            training_pairs = []
            for fb in feedbacks:
                pair = TrainingPairModel(
                    query_text=fb.get("query_text", ""),
                    document_text=fb.get("resource_title", "") + ". " + fb.get("resource_text", ""),
                    label=fb.get("relevance_score", 0.5)
                )
                training_pairs.append(pair)
            
            logger.info(f"üìä {len(training_pairs)} paires d'entra√Ænement r√©cup√©r√©es")
            return training_pairs
            
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration donn√©es: {e}")
            return []
    
    async def fine_tuner_modele(
        self,
        num_epochs: int = 3,
        batch_size: int = 16,
        learning_rate: float = 2e-5
    ) -> Dict:
        """
        Fine-tune le mod√®le cross-encoder sur les feedbacks utilisateurs
        
        Args:
            num_epochs: Nombre d'√©poques d'entra√Ænement
            batch_size: Taille des batchs
            learning_rate: Taux d'apprentissage
            
        Returns:
            Dictionnaire avec les statistiques d'entra√Ænement
        """
        logger.info("üéì D√©but du fine-tuning du cross-encoder...")
        
        try:
            # R√©cup√©rer les donn√©es d'entra√Ænement
            training_pairs = await self.recuperer_donnees_entrainement()
            
            if len(training_pairs) < 10:
                return {
                    "status": "error",
                    "message": f"Pas assez de donn√©es ({len(training_pairs)} paires). Minimum 10 requis."
                }
            
            # Pr√©parer les donn√©es pour sentence-transformers
            train_samples = []
            for pair in training_pairs:
                train_samples.append({
                    'texts': [pair.query_text, pair.document_text],
                    'label': pair.label
                })
            
            # Importer les modules n√©cessaires
            from sentence_transformers import InputExample
            from torch.utils.data import DataLoader
            
            # Cr√©er les InputExamples
            train_examples = [
                InputExample(texts=sample['texts'], label=sample['label'])
                for sample in train_samples
            ]
            
            # Cr√©er le DataLoader
            train_dataloader = DataLoader(
                train_examples, 
                shuffle=True, 
                batch_size=batch_size
            )
            
            # Configuration de l'entra√Ænement
            warmup_steps = int(len(train_dataloader) * num_epochs * 0.1)
            
            logger.info(f"üìö Entra√Ænement sur {len(train_examples)} exemples...")
            logger.info(f"   Epochs: {num_epochs}, Batch size: {batch_size}")
            
            # Fine-tuning
            self.cross_encoder.fit(
                train_dataloader=train_dataloader,
                epochs=num_epochs,
                warmup_steps=warmup_steps,
                output_path=self.model_path,
                show_progress_bar=True
            )
            
            # Sauvegarder les m√©tadonn√©es
            metadata = {
                "model_version": f"finetuned_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                "base_model": self.base_model_name,
                "num_training_samples": len(train_examples),
                "num_epochs": num_epochs,
                "batch_size": batch_size,
                "learning_rate": learning_rate,
                "training_date": datetime.now().isoformat()
            }
            
            with open(os.path.join(self.model_path, "metadata.pkl"), 'wb') as f:
                pickle.dump(metadata, f)
            
            logger.info(f"‚úÖ Fine-tuning termin√©! Mod√®le sauvegard√© dans {self.model_path}")
            
            # Recharger le mod√®le fine-tun√©
            self._charger_modele()
            
            return {
                "status": "success",
                "num_training_samples": len(train_examples),
                "num_epochs": num_epochs,
                "model_path": self.model_path,
                "metadata": metadata
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erreur fine-tuning: {e}")
            return {
                "status": "error",
                "message": str(e)
            }
    
    async def obtenir_statistiques_feedback(self) -> FineTuningStatsModel:
        """
        Retourne les statistiques des feedbacks pour le fine-tuning
        
        Returns:
            Statistiques des feedbacks
        """
        try:
            client = pymongo.MongoClient(self.mongodb_url)
            db = client[self.mongodb_db]
            feedback_col = db[self.feedback_collection]
            
            # Compter les feedbacks
            total = feedback_col.count_documents({})
            likes = feedback_col.count_documents({"feedback_type": "like"})
            dislikes = feedback_col.count_documents({"feedback_type": "dislike"})
            
            client.close()
            
            # Charger les m√©tadonn√©es du mod√®le
            metadata_path = os.path.join(self.model_path, "metadata.pkl")
            model_version = None
            last_training = None
            
            if os.path.exists(metadata_path):
                with open(metadata_path, 'rb') as f:
                    metadata = pickle.load(f)
                    model_version = metadata.get("model_version")
                    training_date_str = metadata.get("training_date")
                    if training_date_str:
                        last_training = datetime.fromisoformat(training_date_str)
            
            stats = FineTuningStatsModel(
                nb_feedbacks_total=total,
                nb_likes=likes,
                nb_dislikes=dislikes,
                nb_training_pairs=likes + dislikes,
                model_version=model_version,
                last_training_date=last_training
            )
            
            return stats
            
        except Exception as e:
            logger.error(f"‚ùå Erreur statistiques: {e}")
            return FineTuningStatsModel(
                nb_feedbacks_total=0,
                nb_likes=0,
                nb_dislikes=0,
                nb_training_pairs=0
            )
    
    def predict_score(self, query: str, document: str) -> float:
        """
        Pr√©dit le score de pertinence pour une paire (query, document)
        
        Args:
            query: Texte de la requ√™te
            document: Texte du document
            
        Returns:
            Score de pertinence
        """
        try:
            score = self.cross_encoder.predict([[query, document]])[0]
            return float(score)
        except Exception as e:
            logger.error(f"‚ùå Erreur pr√©diction: {e}")
            return 0.0
    
    async def recuperer_inferences(self, user_query_id: str) -> List[Dict]:
        """
        R√©cup√®re toutes les inf√©rences pour une requ√™te utilisateur donn√©e
        
        Args:
            user_query_id: ID de la requ√™te utilisateur
            
        Returns:
            Liste des inf√©rences avec leurs scores et feedbacks
        """
        try:
            client = pymongo.MongoClient(self.mongodb_url)
            db = client[self.mongodb_db]
            inference_col = db[self.inference_collection]
            
            # R√©cup√©rer toutes les inf√©rences pour cette requ√™te
            inferences = list(inference_col.find(
                {"user_query_id": user_query_id}
            ).sort("rank", 1))  # Trier par rang croissant
            
            client.close()
            
            # Convertir les ObjectId en string
            for inf in inferences:
                inf['_id'] = str(inf['_id'])
            
            logger.info(f"üìä {len(inferences)} inf√©rences r√©cup√©r√©es pour requ√™te {user_query_id}")
            return inferences
            
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration inf√©rences: {e}")
            return []


# Instance singleton
_reranking_service_instance = None

def get_reranking_service(
    mongodb_url: str, 
    mongodb_db: str,
    model_name: str = "cross-encoder/ms-marco-MiniLM-L-6-v2",
    model_path: str = "models/cross_encoder"
) -> RerankingService:
    """
    Obtenir l'instance du service de re-ranking (singleton)
    
    Args:
        mongodb_url: URL de connexion MongoDB
        mongodb_db: Nom de la base de donn√©es
        model_name: Nom du mod√®le cross-encoder
        model_path: Chemin du mod√®le fine-tun√©
        
    Returns:
        Instance du service de re-ranking
    """
    global _reranking_service_instance
    if _reranking_service_instance is None:
        _reranking_service_instance = RerankingService(
            mongodb_url, 
            mongodb_db, 
            model_name, 
            model_path
        )
    return _reranking_service_instance
